{"deck_name":"CS356_Unit15_Superscalar","slide_number":1,"chunk_index":0,"title":"Unit 15: Superscalar CPUs","summary":"Unit 15: Superscalar CPUs slide explaining Through Static and Dynamic Scheduling","main_text":"Through Static and Dynamic Scheduling","notes_text":"","keywords":["unit","superscalar","cpus","through","static","dynamic","scheduling"],"images":[{"description":"Diagram or figure related to: Unit 15: Superscalar CPUs","labels":[],"position":{"x":0.40017366579177605,"y":0.27167541557305336,"width":0.1996527777777778,"height":0.3194444444444444}}],"layout":{"num_text_boxes":2,"num_images":1,"dominant_visual_type":"mixed"},"metadata":{"course":"CS356","unit":15,"topic":"Superscalar CPUs","importance_score":5,"file_hash":"832bcbf6416184b2c4bb4720eed39d5860057d586681310645ba438e054f42bf"}}
{"deck_name":"CS356_Unit15_Superscalar","slide_number":2,"chunk_index":0,"title":"Full Pipeline: 1 IPC","summary":"Full Pipeline: 1 IPC slide explaining Instruc. i+2 Machine Code Instruc i+1 operands New PC %rdx / sum I-Cache D-Cache ALU Reg. File WB (ADD) PC Decode Fetch (i+3) Decode (i+2) Exec. (i+1) Mem (JE) Write word to %rdx Update PC Use the ALU Fetch next instruc i+3 Decode instruction i+2 and fetch operands ZF OF CF SF Much better than 0.2 IPC (1 instr. / 5 clock cycles) without pipeline Can we do better than 1 IPC? Yes!","main_text":"Instruc. i+2 Machine Code Instruc i+1 operands New PC %rdx / sum I-Cache D-Cache ALU Reg. File WB (ADD) PC Decode Fetch (i+3) Decode (i+2) Exec. (i+1) Mem (JE) Write word to %rdx Update PC Use the ALU Fetch next instruc i+3 Decode instruction i+2 and fetch operands ZF OF CF SF Much better than 0.2 IPC (1 instr. / 5 clock cycles) without pipeline Can we do better than 1 IPC? Yes!","notes_text":"","keywords":["ipc","pc","alu","wb","add","je","zf","of","cf","sf"],"images":[],"layout":{"num_text_boxes":26,"num_images":0,"dominant_visual_type":"text-heavy"},"metadata":{"course":"CS356","unit":15,"topic":"Superscalar CPUs","importance_score":5,"file_hash":"832bcbf6416184b2c4bb4720eed39d5860057d586681310645ba438e054f42bf"}}
{"deck_name":"CS356_Unit15_Superscalar","slide_number":3,"chunk_index":0,"title":"Superscalar CPU","summary":"Superscalar CPU slide explaining When airplanes broke the sound barrier we said they were supersonic When a CPU can complete more than 1 IPC we say that it is superscalar (k-way superscalar = up to k IPC) Superscalar CPUs exploit instruction-level parallelism (ILP) Execution of instructions of a single program/thread in parallel Other forms of parallelism: execute threads on different cores (thread-level), use vector instructions to process multiple data in parallel (data-level, SIMD).","main_text":"When airplanes broke the sound barrier we said they were supersonic When a CPU can complete more than 1 IPC we say that it is superscalar (k-way superscalar = up to k IPC) Superscalar CPUs exploit instruction-level parallelism (ILP) Execution of instructions of a single program/thread in parallel Other forms of parallelism: execute threads on different cores (thread-level), use vector instructions to process multiple data in parallel (data-level, SIMD)","notes_text":"","keywords":["superscalar","cpu","ipc","ilp","instruction-level","parallelism","thread-level","simd","data-level"],"images":[{"description":"Diagram or figure related to: Superscalar CPU","labels":[],"position":{"x":0.13480832910276073,"y":0.2290909090909091,"width":0.7303833417944785,"height":0.6545454545454545}}],"layout":{"num_text_boxes":2,"num_images":1,"dominant_visual_type":"mixed"},"metadata":{"course":"CS356","unit":15,"topic":"Superscalar CPUs","importance_score":5,"file_hash":"832bcbf6416184b2c4bb4720eed39d5860057d586681310645ba438e054f42bf"}}
{"deck_name":"CS356_Unit15_Superscalar","slide_number":4,"chunk_index":0,"title":"Instruction-Level Parallelism","summary":"Instruction-Level Parallelism slide explaining A program defines a sequential ordering of instructions, but in reality many instructions can be executed in parallel. ILP = finding instructions of a program/thread that can be executed in parallel, out-of-order with respect to the original execution. Not always possible to reorder / parallelize! Data Dependencies: Some instructions need data produced by others (“read after write”, RAW). Control Hazards: Cannot execute instructions that are after a conditional jump (unless we have a way to “undo”).","main_text":"A program defines a sequential ordering of instructions, but in reality many instructions can be executed in parallel. ILP = finding instructions of a program/thread that can be executed in parallel, out-of-order with respect to the original execution. Not always possible to reorder / parallelize! Data Dependencies: Some instructions need data produced by others (“read after write”, RAW) Control Hazards: Cannot execute instructions that are after a conditional jump (unless we have a way to “undo”)","notes_text":"","keywords":["instruction-level","parallelism","ilp","out-of-order","data","dependencies","raw","control","hazards"],"images":[],"layout":{"num_text_boxes":1,"num_images":0,"dominant_visual_type":"text-heavy"},"metadata":{"course":"CS356","unit":15,"topic":"Instruction-Level Parallelism","importance_score":5,"file_hash":"832bcbf6416184b2c4bb4720eed39d5860057d586681310645ba438e054f42bf"}}
{"deck_name":"CS356_Unit15_Superscalar","slide_number":5,"chunk_index":0,"title":"Example: Parallel Scheduling","summary":"Example: Parallel Scheduling slide explaining ld 0(%r8), %r9 and %r10, %r11 or %r11, %r13 sub %r14, %r15 add %r10, %r12 je $0, %r12, L1 xor %r15, %rax write %r11 read %r11 write %r15 read %r15 write %r12 read %r12 LD ADD SUB AND JE XOR OR Dependency Graph Note: Our CPU has special “compare & jump” instructions, e.g., “je $0,%r12,L1” jumps to L1 if %r12 is equal to 0.","main_text":"ld 0(%r8), %r9 and %r10, %r11 or %r11, %r13 sub %r14, %r15 add %r10, %r12 je $0, %r12, L1 xor %r15, %rax write %r11 read %r11 write %r15 read %r15 write %r12 read %r12 LD ADD SUB AND JE XOR OR Dependency Graph Note: Our CPU has special “compare & jump” instructions, e.g., “je $0,%r12,L1” jumps to L1 if %r12 is equal to 0","notes_text":"","keywords":["parallel","scheduling","dependency","graph","ld","add","sub","and","je","xor"],"images":[{"description":"Diagram or figure related to: Example: Parallel Scheduling","labels":[],"position":{"x":0.14785745219730942,"y":0.17173913043478262,"width":0.70443168284629,"height":0.7120000000000001}}],"layout":{"num_text_boxes":5,"num_images":1,"dominant_visual_type":"mixed"},"metadata":{"course":"CS356","unit":15,"topic":"Instruction-Level Parallelism","importance_score":6,"file_hash":"832bcbf6416184b2c4bb4720eed39d5860057d586681310645ba438e054f42bf"}}
{"deck_name":"CS356_Unit15_Superscalar","slide_number":6,"chunk_index":0,"title":"Dynamic vs. Static Scheduling","summary":"Dynamic vs. Static Scheduling slide explaining Dynamic Scheduling: The compiler produces a sequence instructions, reordered by the CPU at runtime to execute instructions in parallel using its independent execution units. Static Scheduling: The compiler knows about CPU HW units and decides at compile time the parallel execution schedule. Static scheduling is difficult to compile and cannot exploit runtime events like cache misses.","main_text":"Dynamic Scheduling The compiler produces a sequence instructions, reordered by the CPU at runtime to execute instructions in parallel using its independent execution units (HW for integer ops, float ops, memory load/store) Static Scheduling The compiler knows about CPU HW units and decides (at compile time) the parallel execution schedule Very difficult to write compilers, cannot exploit runtime events of CPU (e.g., do something during a cache miss)","notes_text":"","keywords":["dynamic","static","scheduling","compiler","runtime","execution","units","cache","miss"],"images":[],"layout":{"num_text_boxes":2,"num_images":0,"dominant_visual_type":"text-heavy"},"metadata":{"course":"CS356","unit":15,"topic":"Static Scheduling and VLIW","importance_score":6,"file_hash":"832bcbf6416184b2c4bb4720eed39d5860057d586681310645ba438e054f42bf"}}
{"deck_name":"CS356_Unit15_Superscalar","slide_number":7,"chunk_index":0,"title":"Static Scheduling","summary":"Static Scheduling slide explaining The dependency graph example is scheduled across multiple execution units over three clock cycles; instructions are placed to respect RAW hazards and maximize parallel issue.","main_text":"ld 0(%r8), %r9 and %r10, %r11 or %r11, %r13 sub %r14, %r15 add %r10, %r12 je $0, %r12, L1 xor %r15, %rax write %r11 read %r11 write %r15 read %r15 write %r12 read %r12 LD ADD SUB AND JE XOR OR Clock Cycle 1 Clock Cycle 2 Clock Cycle 3 Execution Unit 1 Execution Unit 2 Execution Unit 3 Execution Unit 4 $ Static Scheduling","notes_text":"","keywords":["static","scheduling","clock","cycle","execution","unit","ld","add","sub","je"],"images":[{"description":"Diagram or figure related to: Static Scheduling","labels":[],"position":{"x":0.1231084142394822,"y":0.14973958333333334,"width":0.7537831715210356,"height":0.7486979166666666}}],"layout":{"num_text_boxes":8,"num_images":1,"dominant_visual_type":"mixed"},"metadata":{"course":"CS356","unit":15,"topic":"Static Scheduling and VLIW","importance_score":6,"file_hash":"832bcbf6416184b2c4bb4720eed39d5860057d586681310645ba438e054f42bf"}}
{"deck_name":"CS356_Unit15_Superscalar","slide_number":8,"chunk_index":0,"title":"VLIW CPUs","summary":"VLIW CPUs slide explaining Very Long Instruction Word machines issue multi-instruction packets per cycle, one per execution unit; the compiler forms these packets and reorders code to achieve up to k IPC with full scheduling.","main_text":"Very Long Instruction Words Issue packets containing many instructions, one for each execution unit of the CPU (LD, AND, SUB, ADD) (—, OR, —, JE) (—, —, XOR, —) The compiler reorders and organizes the instructions in packets. The CPU fetches one packet during each clock cycle and issues its instructions into a pipeline k instr/packet ⇒ k IPC (with full pipeline and full schedule)","notes_text":"","keywords":["vliw","very","long","instruction","words","issue","packets","compiler","ipc"],"images":[],"layout":{"num_text_boxes":2,"num_images":0,"dominant_visual_type":"text-heavy"},"metadata":{"course":"CS356","unit":15,"topic":"Static Scheduling and VLIW","importance_score":6,"file_hash":"832bcbf6416184b2c4bb4720eed39d5860057d586681310645ba438e054f42bf"}}
{"deck_name":"CS356_Unit15_Superscalar","slide_number":9,"chunk_index":0,"title":"Example: 2-Way VLIW CPU","summary":"Example: 2-Way VLIW CPU slide explaining Architecture with separate integer/branch and load/store slots, wide register file access, and an address calculation unit enabling parallel ALU and memory ops in one packet.","main_text":"One issue slot for INT/BRANCH operations & another for LD/ST instructions I-Cache reads out an entire issue packet (1 or 2 instructions) HW is added to allow many registers to be accessed at one time Additional “Address Calculation Unit” (just a simple adder) to add offset in parallel with integer ALU calculations (e.g., may have ld & add in a packet) Issue Packet = More than 1 instruction Integer Slot LD/ST Slot","notes_text":"","keywords":["vliw","2-way","issue","packet","integer","branch","ld/st","address","calc"],"images":[{"description":"Diagram or figure related to: Example: 2-Way VLIW CPU","labels":[],"position":{"x":0.0862890249194333,"y":0.2706388888888889,"width":0.32708333333333334,"height":0.53125}},{"description":"Diagram or figure related to: Example: 2-Way VLIW CPU","labels":[],"position":{"x":0.5087070782030702,"y":0.2706388888888889,"width":0.3270833333333333,"height":0.53125}}],"layout":{"num_text_boxes":6,"num_images":2,"dominant_visual_type":"mixed"},"metadata":{"course":"CS356","unit":15,"topic":"Static Scheduling and VLIW","importance_score":6,"file_hash":"832bcbf6416184b2c4bb4720eed39d5860057d586681310645ba438e054f42bf"}}
{"deck_name":"CS356_Unit15_Superscalar","slide_number":10,"chunk_index":0,"title":"Scheduling Rules","summary":"Scheduling Rules slide explaining Rules for VLIW issue packets: no forwarding within a packet, full forwarding to later packets, and a mandatory one-cycle stall after a load when the next instruction depends on it.","main_text":"1. No forwarding between instructions in an issue packet 2. Full forwarding to instructions that follow (behind in the pipeline) 3. 1 stall cycle necessary when LD is followed by a dependent instr. (we need a clock cycle to retrieve data from cache)","notes_text":"","keywords":["scheduling","rules","forwarding","issue","packet","stall","ld","dependent"],"images":[{"description":"Diagram or figure related to: Scheduling Rules","labels":[],"position":{"x":0.11613654223968567,"y":0.17447916666666666,"width":0.7677269155206287,"height":0.55}}],"layout":{"num_text_boxes":4,"num_images":1,"dominant_visual_type":"mixed"},"metadata":{"course":"CS356","unit":15,"topic":"Static Scheduling and VLIW","importance_score":6,"file_hash":"832bcbf6416184b2c4bb4720eed39d5860057d586681310645ba438e054f42bf"}}
{"deck_name":"CS356_Unit15_Superscalar","slide_number":11,"chunk_index":0,"title":"Example: Rules 1 & 2","summary":"Example: Rules 1 & 2 slide explaining Shows RAW vs RAR/WAR cases demonstrating that stores in the same packet can’t see results of adds, so dependent stores must be scheduled in later packets.","main_text":"In the schedule at the top, st %r9,0(%rdi) will not receive the new value of %r9 produced by add $5, %r9! It will use the old value… (no forwarding between instructions in an issue packet) Since the intent of the program is to store the new value, we need to schedule st in the next packet (example at the bottom) The new value will be forwarded on the pipeline (full forwarding to instructions that follow) Original program (RAW dependency) In this example, st %r9,0(%rdi) should use the old value of %r9 (before the change by add). We can schedule st in a previous packet (top schedule) In the same packet as add, since it won’t see the change anyway (bottom schedule) Original program (RAR/WAR dependency)","notes_text":"","keywords":["raw","rar","war","rules","forwarding","packet","store","add"],"images":[{"description":"Diagram or figure related to: Example: Rules 1 & 2","labels":[],"position":{"x":0.11912569395442359,"y":0.1171875,"width":0.7617486120911528,"height":0.796875}}],"layout":{"num_text_boxes":7,"num_images":1,"dominant_visual_type":"mixed"},"metadata":{"course":"CS356","unit":15,"topic":"Data Hazards and Register Renaming","importance_score":6,"file_hash":"832bcbf6416184b2c4bb4720eed39d5860057d586681310645ba438e054f42bf"}}
{"deck_name":"CS356_Unit15_Superscalar","slide_number":12,"chunk_index":0,"title":"Example: Rule 3","summary":"Example: Rule 3 slide explaining Demonstrates the stall requirement after a load when the immediately following instruction is RAW-dependent on the loaded value.","main_text":"In this example, ld 0(%rdi), %r9 reads a value from the cache which is needed by add $5, %r9 We cannot schedule add in the packet immediately after ld (1 stall cycle necessary when LD is followed by a dependent instr.) We have to skip at least one clock cycle or more (bottom schedule) Original program (RAW dependency)","notes_text":"","keywords":["rule","stall","load","raw","dependent","packet","cache"],"images":[{"description":"Diagram or figure related to: Example: Rule 3","labels":[],"position":{"x":0.09914169863072966,"y":0.2265625,"width":0.8017166027385407,"height":0.654296875}}],"layout":{"num_text_boxes":5,"num_images":1,"dominant_visual_type":"mixed"},"metadata":{"course":"CS356","unit":15,"topic":"Static Scheduling and VLIW","importance_score":6,"file_hash":"832bcbf6416184b2c4bb4720eed39d5860057d586681310645ba438e054f42bf"}}
{"deck_name":"CS356_Unit15_Superscalar","slide_number":13,"chunk_index":0,"title":"Example: Scheduling","summary":"Example: Scheduling slide explaining Presents a loop in C and assembly and a static schedule achieving IPC≈1.2 without changing code, by moving independent instructions into parallel issue packets.","main_text":"# %rdi = A # %esi = n = # of iterations L1: ld 0(%rdi),%r9 add $5,%r9 st %r9,0(%rdi) add $4,%rdi add $-1,%esi jne $0,%esi,L1 void f1(int *A, int n) { do { *A += 5; A++; n--; } while (n != 0); } w/o modifying original code but with code movement IPC = 6 instrucs. / 5 cycles = 1.2","notes_text":"","keywords":["scheduling","ipc","loop","code","movement","issue","packet","assembly"],"images":[],"layout":{"num_text_boxes":2,"num_images":0,"dominant_visual_type":"text-heavy"},"metadata":{"course":"CS356","unit":15,"topic":"Static Scheduling and VLIW","importance_score":6,"file_hash":"832bcbf6416184b2c4bb4720eed39d5860057d586681310645ba438e054f42bf"}}
{"deck_name":"CS356_Unit15_Superscalar","slide_number":14,"chunk_index":0,"title":"Example: Execution On The Pipeline","summary":"Example: Execution On The Pipeline slide explaining Shows how the scheduled packets flow through integer and load/store slots, with nops inserted to satisfy forwarding and stall rules.","main_text":"Issue Packet = More than 1 instruction Integer Slot LD/ST Slot INT/BRANCH LD/ST add $4,%rdi st %r9,0(%rdi) ld 0(%rdi),%r9 add $-1,%esi add $5,%r9 jne $0,%esi,L1 nop nop nop nop","notes_text":"","keywords":["pipeline","issue","packet","integer","ld/st","nops","forwarding","stall"],"images":[{"description":"Diagram or figure related to: Example: Execution On The Pipeline","labels":[],"position":{"x":0.06918710230518818,"y":0.16927083333333334,"width":0.8616257953896237,"height":0.6760416666666668}}],"layout":{"num_text_boxes":4,"num_images":1,"dominant_visual_type":"mixed"},"metadata":{"course":"CS356","unit":15,"topic":"Static Scheduling and VLIW","importance_score":6,"file_hash":"832bcbf6416184b2c4bb4720eed39d5860057d586681310645ba438e054f42bf"}}
{"deck_name":"CS356_Unit15_Superscalar","slide_number":15,"chunk_index":0,"title":"Example: Better Schedule","summary":"Example: Better Schedule slide explaining Compares original vs modified code plus movement, improving IPC from ~1.2 to ~1.5 by changing instructions and packing them more efficiently.","main_text":"w/o modifying original code but with code movement IPC = 6 instrucs. / 5 cycles = 1.2 w/ modifications and code movement IPC = 6 instrucs. / 4 cycle = 1.5","notes_text":"","keywords":["better","schedule","ipc","code","movement","modifications"],"images":[],"layout":{"num_text_boxes":3,"num_images":0,"dominant_visual_type":"text-heavy"},"metadata":{"course":"CS356","unit":15,"topic":"Static Scheduling and VLIW","importance_score":6,"file_hash":"832bcbf6416184b2c4bb4720eed39d5860057d586681310645ba438e054f42bf"}}
{"deck_name":"CS356_Unit15_Superscalar","slide_number":16,"chunk_index":0,"title":"Loop Unrolling","summary":"Loop Unrolling slide explaining Introduces unrolling to expose ILP across independent loop iterations, reducing branch/overhead and enabling more parallel scheduling.","main_text":"Often not enough ILP in a single iteration (body) of a loop However, different iterations of the loop are often independent and can thus be run in parallel This parallelism can be exposed in static issue machines via loop unrolling Copy the body of the loop k times and iterate only n/k times Instructions from different body iterations can be run in parallel void f1(int *A, int n) { // assume n is a multiple of 4 do { // loop unrolled 4 times *A += 5; *(A+1) += 5; *(A+2) += 5; *(A+3) += 5; A += 4; n -= 4; } while (n != 0); }","notes_text":"","keywords":["loop","unrolling","ilp","iterations","parallel","static","issue","machines"],"images":[],"layout":{"num_text_boxes":3,"num_images":0,"dominant_visual_type":"text-heavy"},"metadata":{"course":"CS356","unit":15,"topic":"Static Scheduling and VLIW","importance_score":6,"file_hash":"832bcbf6416184b2c4bb4720eed39d5860057d586681310645ba438e054f42bf"}}
{"deck_name":"CS356_Unit15_Superscalar","slide_number":17,"chunk_index":0,"title":"Loop Unrolling: Instructions","summary":"Loop Unrolling: Instructions slide explaining Shows original vs unrolled assembly, highlighting reduced overhead but shared temp register %r9 creating name dependencies.","main_text":"Original Code Unrolled Code Side effect of unrolling: less overhead (branches & counter/pointer updates) We cannot execute the unrolled instructions in parallel yet … Data dependency: they all use the register %r9 to store a temporary value! We can use different registers for each unrolled body of the for loop We must use 12-16=-4 as the last st offset because of the update to %rdi","notes_text":"","keywords":["unrolled","assembly","overhead","branches","name","dependencies","register","r9"],"images":[],"layout":{"num_text_boxes":3,"num_images":0,"dominant_visual_type":"text-heavy"},"metadata":{"course":"CS356","unit":15,"topic":"Data Hazards and Register Renaming","importance_score":6,"file_hash":"832bcbf6416184b2c4bb4720eed39d5860057d586681310645ba438e054f42bf"}}
{"deck_name":"CS356_Unit15_Superscalar","slide_number":18,"chunk_index":0,"title":"Loop Unrolling: Register Renaming","summary":"Loop Unrolling: Register Renaming slide explaining Uses distinct registers (r9–r12) for each unrolled iteration to remove false dependencies, yielding IPC≈1.875.","main_text":"# %rdi = A # %esi = n = # of iterations L1: ld 0(%rdi), %r9 add $5, %r9 st %r9,0(%rdi) ld 4(%rdi), %r10 add $5, %r10 st %r10,4(%rdi) ld 8(%rdi), %r11 add $5, %r11 st %r11,8(%rdi) ld 12(%rdi), %r12 add $5, %r12 st %r12,12(%rdi) add $16,%rdi add $-4,%esi jne $0,%esi,L1 With Loop Unrolling and Register Renaming: IPC = 15 instrucs. / 8 cycle = 1.875","notes_text":"","keywords":["register","renaming","unrolling","ipc","false","dependencies","r9","r10","r11","r12"],"images":[],"layout":{"num_text_boxes":1,"num_images":0,"dominant_visual_type":"text-heavy"},"metadata":{"course":"CS356","unit":15,"topic":"Data Hazards and Register Renaming","importance_score":7,"file_hash":"832bcbf6416184b2c4bb4720eed39d5860057d586681310645ba438e054f42bf"}}
{"deck_name":"CS356_Unit15_Superscalar","slide_number":19,"chunk_index":0,"title":"More on Data Hazards: WAR & WAW","summary":"More on Data Hazards: WAR & WAW slide explaining Defines WAR and WAW as anti-dependencies (name hazards) that arise under out-of-order execution and are solved via register renaming.","main_text":"When executing code out-of-order (e.g., the unrolled bodies in parallel), we must deal with WAR (Write-After-Read) and WAW (Write-After-Write) hazards in addition to RAW hazards In loop unrolling, there were only WAR/WAW hazards between unrolled bodies These are not true hazards (no real dependency) but simply conflicts because we want to use the same register… called “name dependencies” or anti-dependences!","notes_text":"","keywords":["war","waw","raw","anti-dependencies","name","hazards","out-of-order","renaming"],"images":[],"layout":{"num_text_boxes":2,"num_images":0,"dominant_visual_type":"text-heavy"},"metadata":{"course":"CS356","unit":15,"topic":"Data Hazards and Register Renaming","importance_score":6,"file_hash":"832bcbf6416184b2c4bb4720eed39d5860057d586681310645ba438e054f42bf"}}
{"deck_name":"CS356_Unit15_Superscalar","slide_number":20,"chunk_index":0,"title":"Summary: Data Dependency Hazards","summary":"Summary: Data Dependency Hazards slide explaining Summarizes RAW as true dependencies, WAR/WAW as anti-dependencies fixed by renaming, and RAR as harmless.","main_text":"RAW = Only real data dependency Must be respected in terms of code movement and ordering Forwarding reduces latency of dependent instructions WAW and WAR = Anti-dependencies Solved by using register renaming RAR = No issues / dependencies","notes_text":"","keywords":["raw","war","waw","rar","forwarding","latency","renaming","dependencies"],"images":[],"layout":{"num_text_boxes":2,"num_images":0,"dominant_visual_type":"text-heavy"},"metadata":{"course":"CS356","unit":15,"topic":"Data Hazards and Register Renaming","importance_score":6,"file_hash":"832bcbf6416184b2c4bb4720eed39d5860057d586681310645ba438e054f42bf"}}
{"deck_name":"CS356_Unit15_Superscalar","slide_number":21,"chunk_index":0,"title":"Loop Unrolling: Limitations","summary":"Loop Unrolling: Limitations slide explaining Notes tradeoffs: larger code size, more registers needed, and memory hazards when addresses can’t be disambiguated, limiting safe reordering.","main_text":"Loop unrolling increases code size Register renaming may require more hardware registers Must have independence between loop bodies Dependencies can occur through memory (memory hazard) If the compiler cannot disambiguate memory references (i.e., ensure that they use different addresses), it cannot reorder ld/st (RAW), st/ld (WAR), st/st (WAW) We moved the 2nd ‘ld’ up to enhance performance... Is it equivalent? No! Need to wait for st %edx,0(%rsi)!!","notes_text":"","keywords":["limitations","code","size","memory","hazard","disambiguate","reorder","raw","war","waw"],"images":[{"description":"Diagram or figure related to: Loop Unrolling: Limitations","labels":[],"position":{"x":0.0957664995822894,"y":0.47265625,"width":0.808466, "height":0.39}}],"layout":{"num_text_boxes":3,"num_images":1,"dominant_visual_type":"mixed"},"metadata":{"course":"CS356","unit":15,"topic":"Static Scheduling and VLIW","importance_score":6,"file_hash":"832bcbf6416184b2c4bb4720eed39d5860057d586681310645ba438e054f42bf"}}
{"deck_name":"CS356_Unit15_Superscalar","slide_number":22,"chunk_index":0,"title":"Static Scheduling: Summary","summary":"Static Scheduling: Summary slide explaining Recaps compiler-led reordering/unrolling for multi-issue CPUs, with pros (simpler HW) and cons (complex compilers, recompilation, no runtime adaptation).","main_text":"Compiler is in charge of reordering, renaming, unrolling original program code to achieve better performance CPU is designed to fetch/decode/execute multiple instructions per cycle in the order determined by the compiler HW can be simpler and faster/smaller (more cores, higher clock rate) Requires recompilation for different HW architectures Complex compilers Cannot exploit runtime events (e.g., do something else during cache miss) Itanium2 Case Study 6 ways (IPC <= 6) Units: 6 Int, 4 LD/ST, 3 Branch, 2 FP 128 64-bit registers 128 float registers 12 MB L3 cache Don Knuth quote criticizing compiler difficulty.","notes_text":"","keywords":["static","scheduling","compiler","multi-issue","itanium","ipc","recompilation","runtime"],"images":[{"description":"Diagram or figure related to: Static Scheduling: Summary","labels":[],"position":{"x":0.06024115384207595,"y":0.56875,"width":0.8795176923158481,"height":0.334375}}],"layout":{"num_text_boxes":4,"num_images":1,"dominant_visual_type":"mixed"},"metadata":{"course":"CS356","unit":15,"topic":"Static Scheduling and VLIW","importance_score":6,"file_hash":"832bcbf6416184b2c4bb4720eed39d5860057d586681310645ba438e054f42bf"}}
{"deck_name":"CS356_Unit15_Superscalar","slide_number":23,"chunk_index":0,"title":"Dynamic Scheduling","summary":"Dynamic Scheduling slide explaining Introduces dynamic scheduling as HW-driven reordering to overlap independent instructions and hide stalls, especially from memory latency.","main_text":"Dynamic Scheduling","notes_text":"","keywords":["dynamic","scheduling"],"images":[],"layout":{"num_text_boxes":1,"num_images":0,"dominant_visual_type":"text-heavy"},"metadata":{"course":"CS356","unit":15,"topic":"Dynamic Scheduling / Out-of-Order Execution","importance_score":5,"file_hash":"832bcbf6416184b2c4bb4720eed39d5860057d586681310645ba438e054f42bf"}}
{"deck_name":"CS356_Unit15_Superscalar","slide_number":24,"chunk_index":0,"title":"Overcoming Memory Latency","summary":"Overcoming Memory Latency slide explaining Shows that cache misses force in-order pipelines to stall all following instructions, potentially for hundreds of cycles.","main_text":"What happens to instruction execution if we have a cache miss? All instructions behind us need to stall! Could take potentially hundreds of clock cycles to fetch the data ld 0(%rdi),%rcx Miss STALL STALL STALL","notes_text":"","keywords":["memory","latency","cache","miss","stall","in-order"],"images":[{"description":"Diagram or figure related to: Overcoming Memory Latency","labels":[],"position":{"x":0.055,"y":0.28,"width":0.89,"height":0.5}}],"layout":{"num_text_boxes":3,"num_images":1,"dominant_visual_type":"mixed"},"metadata":{"course":"CS356","unit":15,"topic":"Dynamic Scheduling / Out-of-Order Execution","importance_score":6,"file_hash":"832bcbf6416184b2c4bb4720eed39d5860057d586681310645ba438e054f42bf"}}
{"deck_name":"CS356_Unit15_Superscalar","slide_number":25,"chunk_index":0,"title":"Out-of-Order CPUs","summary":"Out-of-Order CPUs slide explaining Explains executing independent instructions past stalled ones by building dependency graphs at runtime, known as out-of-order (dynamic) scheduling.","main_text":"Idea: Processor can find dependencies as instructions are fetched/decoded and execute independent instructions that come after stalled instructions Known as Out-of-Order Execution or Dynamic Scheduling HW will determine the “dependency” graph at runtime and as long as an instruction isn't waiting for an earlier instruction, let it execute!","notes_text":"","keywords":["out-of-order","dynamic","scheduling","dependencies","runtime","graph","stall"],"images":[],"layout":{"num_text_boxes":1,"num_images":0,"dominant_visual_type":"text-heavy"},"metadata":{"course":"CS356","unit":15,"topic":"Dynamic Scheduling / Out-of-Order Execution","importance_score":8,"file_hash":"832bcbf6416184b2c4bb4720eed39d5860057d586681310645ba438e054f42bf"}}
{"deck_name":"CS356_Unit15_Superscalar","slide_number":26,"chunk_index":0,"title":"Solution: Tomasulo’s Algorithm","summary":"Solution: Tomasulo’s Algorithm slide explaining Presents a simplified Tomasulo block diagram with instruction queues, functional units, register status tracking, and a common data bus for dynamic scheduling.","main_text":"Block Diagram adapted from Prof. Dubois. Components: I-Cache, Register Status Table, Instruction Queue, Issue Unit, Dispatch, Integer/Branch unit, D-Cache, Div, Mul, per-unit queues (Int, L/S, Div, Mult), Common Data Bus. Fetch multiple instructions per cycle in program order. Decode/dispatch tracking dependencies. Instructions wait in queues until unit free and operands ready. Multiple results broadcast/written back per cycle. Register status tracks latest producer to solve RAW/WAR/WAW. Instructions with all data may execute out of order.","notes_text":"","keywords":["tomasulo","algorithm","instruction","queue","register","status","common","data","bus","dynamic"],"images":[{"description":"Diagram or figure related to: Solution: Tomasulo’s Algorithm","labels":[],"position":{"x":0.05,"y":0.13,"width":0.9,"height":0.74}}],"layout":{"num_text_boxes":6,"num_images":1,"dominant_visual_type":"mixed"},"metadata":{"course":"CS356","unit":15,"topic":"Dynamic Scheduling / Out-of-Order Execution","importance_score":8,"file_hash":"832bcbf6416184b2c4bb4720eed39d5860057d586681310645ba438e054f42bf"}}
{"deck_name":"CS356_Unit15_Superscalar","slide_number":27,"chunk_index":0,"title":"Execution (1/10)","summary":"Execution (1/10) slide explaining Step-by-step Tomasulo dispatch where the first load is tagged and placed in a queue while updating the register status table.","main_text":"Shows initial dispatch of instruction 1: ld 0(%rdx), %r8. The LD is assigned unique tag 1 and updates the register status table entry for r8 to indicate a pending producer. Later instructions will reference tag 1 for r8.","notes_text":"","keywords":["execution","dispatch","load","tag","register","status","table","tomasulo"],"images":[{"description":"Diagram or figure related to: Execution (1/10)","labels":[],"position":{"x":0.05,"y":0.12,"width":0.9,"height":0.76}}],"layout":{"num_text_boxes":7,"num_images":1,"dominant_visual_type":"mixed"},"metadata":{"course":"CS356","unit":15,"topic":"Dynamic Scheduling / Out-of-Order Execution","importance_score":8,"file_hash":"832bcbf6416184b2c4bb4720eed39d5860057d586681310645ba438e054f42bf"}}
{"deck_name":"CS356_Unit15_Superscalar","slide_number":28,"chunk_index":0,"title":"Execution (2/10)","summary":"Execution (2/10) slide explaining Dispatches an ADD dependent on the earlier LD, assigns tag 2, and updates r8’s latest-producer entry.","main_text":"Instruction 2 (add $1,%r8) dispatches with tag 2. It sees r8 is being produced by tag 1 so it waits for that result, then becomes the latest producer of r8 by updating the register status table to tag 2.","notes_text":"","keywords":["execution","add","dependent","tag","latest","producer","r8"],"images":[{"description":"Diagram or figure related to: Execution (2/10)","labels":[],"position":{"x":0.05,"y":0.12,"width":0.9,"height":0.76}}],"layout":{"num_text_boxes":8,"num_images":1,"dominant_visual_type":"mixed"},"metadata":{"course":"CS356","unit":15,"topic":"Dynamic Scheduling / Out-of-Order Execution","importance_score":8,"file_hash":"832bcbf6416184b2c4bb4720eed39d5860057d586681310645ba438e054f42bf"}}
{"deck_name":"CS356_Unit15_Superscalar","slide_number":29,"chunk_index":0,"title":"Execution (3/10)","summary":"Execution (3/10) slide explaining Dispatches a store waiting on the ADD result via tag matching; stores don’t update the register status table.","main_text":"Instruction 3 (st %r8,0(%rdx)) dispatches. It checks RST, sees r8 produced by tag 2, and waits for that value. Since ST writes memory not a register, it does not change RST.","notes_text":"","keywords":["execution","store","rst","tag","waiting","memory"],"images":[{"description":"Diagram or figure related to: Execution (3/10)","labels":[],"position":{"x":0.05,"y":0.12,"width":0.9,"height":0.76}}],"layout":{"num_text_boxes":8,"num_images":1,"dominant_visual_type":"mixed"},"metadata":{"course":"CS356","unit":15,"topic":"Dynamic Scheduling / Out-of-Order Execution","importance_score":8,"file_hash":"832bcbf6416184b2c4bb4720eed39d5860057d586681310645ba438e054f42bf"}}
{"deck_name":"CS356_Unit15_Superscalar","slide_number":30,"chunk_index":0,"title":"Execution (4/10)","summary":"Execution (4/10) slide explaining Explains that the cache-missing LD stalls dependent ADD/ST while independent later instructions may proceed.","main_text":"Because instruction 1 LD misses in cache, it may take hundreds of cycles. Dependent instructions 2 (ADD) and 3 (ST) stall waiting for tagged results, and cannot execute until LD completes.","notes_text":"","keywords":["execution","cache","miss","stall","dependent","ld","add","st"],"images":[{"description":"Diagram or figure related to: Execution (4/10)","labels":[],"position":{"x":0.05,"y":0.12,"width":0.9,"height":0.76}}],"layout":{"num_text_boxes":8,"num_images":1,"dominant_visual_type":"mixed"},"metadata":{"course":"CS356","unit":15,"topic":"Dynamic Scheduling / Out-of-Order Execution","importance_score":8,"file_hash":"832bcbf6416184b2c4bb4720eed39d5860057d586681310645ba438e054f42bf"}}
{"deck_name":"CS356_Unit15_Superscalar","slide_number":31,"chunk_index":0,"title":"Execution (5/10)","summary":"Execution (5/10) slide explaining Dispatches the next LD/ADD/ST sequence; RST entries update to new tags while stalled ops wait.","main_text":"A second LD (tag 4), ADD (tag 5), and ST (tag 6) are dispatched. The LD sets r9’s producer to 4, then ADD updates it to 5, showing how RST tracks latest producers across multiple in-flight instructions.","notes_text":"","keywords":["execution","dispatch","rst","tags","producer","in-flight"],"images":[{"description":"Diagram or figure related to: Execution (5/10)","labels":[],"position":{"x":0.05,"y":0.12,"width":0.9,"height":0.76}}],"layout":{"num_text_boxes":9,"num_images":1,"dominant_visual_type":"mixed"},"metadata":{"course":"CS356","unit":15,"topic":"Dynamic Scheduling / Out-of-Order Execution","importance_score":8,"file_hash":"832bcbf6416184b2c4bb4720eed39d5860057d586681310645ba438e054f42bf"}}
{"deck_name":"CS356_Unit15_Superscalar","slide_number":32,"chunk_index":0,"title":"Execution (6/10)","summary":"Execution (6/10) slide explaining Shows that LD #4 can execute out of order while earlier miss is pending, assuming the cache supports multiple outstanding misses.","main_text":"LD #4 has all operands and its cache request can proceed even though LD #1 is stalled. This demonstrates out-of-order execution and memory-level parallelism.","notes_text":"","keywords":["execution","out-of-order","ld","cache","miss","parallelism"],"images":[{"description":"Diagram or figure related to: Execution (6/10)","labels":[],"position":{"x":0.05,"y":0.12,"width":0.9,"height":0.76}}],"layout":{"num_text_boxes":9,"num_images":1,"dominant_visual_type":"mixed"},"metadata":{"course":"CS356","unit":15,"topic":"Dynamic Scheduling / Out-of-Order Execution","importance_score":8,"file_hash":"832bcbf6416184b2c4bb4720eed39d5860057d586681310645ba438e054f42bf"}}
{"deck_name":"CS356_Unit15_Superscalar","slide_number":33,"chunk_index":0,"title":"Execution (7/10)","summary":"Execution (7/10) slide explaining Broadcast of LD #4’s result enables dependent ADD #5; meanwhile newer independent instructions are dispatched.","main_text":"Once LD #4 reads from cache, it broadcasts its value on the common data bus. ADD #5 captures it and can execute; subsequent instructions continue to dispatch during the stall window.","notes_text":"","keywords":["execution","broadcast","common","data","bus","dependent","add"],"images":[{"description":"Diagram or figure related to: Execution (7/10)","labels":[],"position":{"x":0.05,"y":0.12,"width":0.9,"height":0.76}}],"layout":{"num_text_boxes":9,"num_images":1,"dominant_visual_type":"mixed"},"metadata":{"course":"CS356","unit":15,"topic":"Dynamic Scheduling / Out-of-Order Execution","importance_score":8,"file_hash":"832bcbf6416184b2c4bb4720eed39d5860057d586681310645ba438e054f42bf"}}
{"deck_name":"CS356_Unit15_Superscalar","slide_number":34,"chunk_index":0,"title":"Execution (8/10)","summary":"Execution (8/10) slide explaining ADD #5 executes after receiving operands, broadcasts its result, and clears r9’s RST entry as the latest producer commits.","main_text":"ADD #5 now has operands, executes, broadcasts tag/result, enabling ST #6 to take the value. The true register r9 is updated and its RST entry is reset to nil.","notes_text":"","keywords":["execution","add","broadcast","st","rst","commit"],"images":[{"description":"Diagram or figure related to: Execution (8/10)","labels":[],"position":{"x":0.05,"y":0.12,"width":0.9,"height":0.76}}],"layout":{"num_text_boxes":9,"num_images":1,"dominant_visual_type":"mixed"},"metadata":{"course":"CS356","unit":15,"topic":"Dynamic Scheduling / Out-of-Order Execution","importance_score":8,"file_hash":"832bcbf6416184b2c4bb4720eed39d5860057d586681310645ba438e054f42bf"}}
{"deck_name":"CS356_Unit15_Superscalar","slide_number":35,"chunk_index":0,"title":"Execution (9/10)","summary":"Execution (9/10) slide explaining ST #6 and independent pointer update ADD #7 execute out of order without WAR hazards due to value capture at dispatch.","main_text":"ST #6 can execute since it has data. ADD #7 updating rdi is independent; ST already captured the old rdi address so there is no WAR hazard.","notes_text":"","keywords":["execution","store","war","hazard","independent","address","capture"],"images":[{"description":"Diagram or figure related to: Execution (9/10)","labels":[],"position":{"x":0.05,"y":0.12,"width":0.9,"height":0.76}}],"layout":{"num_text_boxes":9,"num_images":1,"dominant_visual_type":"mixed"},"metadata":{"course":"CS356","unit":15,"topic":"Dynamic Scheduling / Out-of-Order Execution","importance_score":8,"file_hash":"832bcbf6416184b2c4bb4720eed39d5860057d586681310645ba438e054f42bf"}}
{"deck_name":"CS356_Unit15_Superscalar","slide_number":36,"chunk_index":0,"title":"Execution (10/10)","summary":"Execution (10/10) slide explaining When the original miss resolves, LD #1 broadcasts, allowing its dependent ADD #2 then ST #3 to complete.","main_text":"MISS RESOLVED: Once LD #1 completes, it broadcasts its value; dependent ADD #2 executes next and then ST #3 can proceed. Shows final completion order under Tomasulo.","notes_text":"","keywords":["execution","miss","resolved","broadcast","dependent","completion"],"images":[{"description":"Diagram or figure related to: Execution (10/10)","labels":[],"position":{"x":0.05,"y":0.12,"width":0.9,"height":0.76}}],"layout":{"num_text_boxes":9,"num_images":1,"dominant_visual_type":"mixed"},"metadata":{"course":"CS356","unit":15,"topic":"Dynamic Scheduling / Out-of-Order Execution","importance_score":8,"file_hash":"832bcbf6416184b2c4bb4720eed39d5860057d586681310645ba438e054f42bf"}}
{"deck_name":"CS356_Unit15_Superscalar","slide_number":37,"chunk_index":0,"title":"Dynamic Scheduling: Summary","summary":"Dynamic Scheduling: Summary slide explaining Summarizes HW-driven runtime dependency detection and out-of-order execution to keep units busy despite stalls.","main_text":"Burden of scheduling code for parallelism is placed on the CPU HW and is performed dynamically at runtime (as the program runs) Goal is for HW to determine data dependencies and let independent instructions execute even if previous instructions are stalled","notes_text":"","keywords":["dynamic","scheduling","runtime","dependencies","out-of-order","hw"],"images":[],"layout":{"num_text_boxes":1,"num_images":0,"dominant_visual_type":"text-heavy"},"metadata":{"course":"CS356","unit":15,"topic":"Dynamic Scheduling / Out-of-Order Execution","importance_score":6,"file_hash":"832bcbf6416184b2c4bb4720eed39d5860057d586681310645ba438e054f42bf"}}
{"deck_name":"CS356_Unit15_Superscalar","slide_number":38,"chunk_index":0,"title":"Speculative Execution","summary":"Speculative Execution slide explaining Introduces control dependencies, basic blocks, and why branch prediction is needed to extend out-of-order scheduling across blocks.","main_text":"Control dependencies really limit our window of possible instructions to overlap Cannot reorder an instruction if we are unsure it should execute Basic Block = Sequence of instructions that will always be executed together No conditional branches out No branch targets coming in Also called straight-line code Average size: 5–7 instructions Instructions in a basic block can be overlapped if there are no data dependencies","notes_text":"","keywords":["speculative","execution","control","dependencies","basic","block","branch","prediction"],"images":[],"layout":{"num_text_boxes":2,"num_images":0,"dominant_visual_type":"text-heavy"},"metadata":{"course":"CS356","unit":15,"topic":"Speculative Execution and Reorder Buffer","importance_score":7,"file_hash":"832bcbf6416184b2c4bb4720eed39d5860057d586681310645ba438e054f42bf"}}
{"deck_name":"CS356_Unit15_Superscalar","slide_number":39,"chunk_index":0,"title":"Issue: Branch Prediction","summary":"Issue: Branch Prediction slide explaining Explains speculative execution across basic blocks and the need to undo completed wrong-path instructions.","main_text":"To apply out-of-order execution across basic blocks we need to predict outcomes of conditional jumps (speculative execution). If predictions are wrong, we can’t just flush a pipeline because wrong-path instructions may have completed. Need a way to undo effects.","notes_text":"","keywords":["branch","prediction","speculative","execution","wrong-path","undo","basic","blocks"],"images":[],"layout":{"num_text_boxes":2,"num_images":0,"dominant_visual_type":"text-heavy"},"metadata":{"course":"CS356","unit":15,"topic":"Speculative Execution and Reorder Buffer","importance_score":8,"file_hash":"832bcbf6416184b2c4bb4720eed39d5860057d586681310645ba438e054f42bf"}}
{"deck_name":"CS356_Unit15_Superscalar","slide_number":40,"chunk_index":0,"title":"Issue: Hardware Exceptions","summary":"Issue: Hardware Exceptions slide explaining Shows problem of exceptions in older instructions after younger ones complete; motivates speculative execution with commit/rollback.","main_text":"If an exception (e.g., page fault) occurs in an earlier instruction after later ones completed, restarting can cause younger instructions to execute twice. Solution: speculative execution with commit unit and ability to rollback.","notes_text":"","keywords":["hardware","exceptions","page","fault","rollback","commit","speculative"],"images":[{"description":"Diagram or figure related to: Issue: Hardware Exceptions","labels":[],"position":{"x":0.06,"y":0.27,"width":0.88,"height":0.55}}],"layout":{"num_text_boxes":3,"num_images":1,"dominant_visual_type":"mixed"},"metadata":{"course":"CS356","unit":15,"topic":"Speculative Execution and Reorder Buffer","importance_score":8,"file_hash":"832bcbf6416184b2c4bb4720eed39d5860057d586681310645ba438e054f42bf"}}
{"deck_name":"CS356_Unit15_Superscalar","slide_number":41,"chunk_index":0,"title":"Reorder Buffer","summary":"Reorder Buffer slide explaining Introduces ROB as a commit unit buffering out-of-order results and committing in-order to support rollback on exceptions/mispredictions.","main_text":"Re-Order Buffer (ROB): temporarily buffers results of instructions until earlier (older) instructions complete and write back in order. Provides in-order commit, queues for functional units, and allows flushing younger entries on error.","notes_text":"","keywords":["reorder","buffer","rob","commit","in-order","out-of-order","flush"],"images":[{"description":"Diagram or figure related to: Reorder Buffer","labels":[],"position":{"x":0.05,"y":0.12,"width":0.9,"height":0.74}}],"layout":{"num_text_boxes":6,"num_images":1,"dominant_visual_type":"mixed"},"metadata":{"course":"CS356","unit":15,"topic":"Speculative Execution and Reorder Buffer","importance_score":8,"file_hash":"832bcbf6416184b2c4bb4720eed39d5860057d586681310645ba438e054f42bf"}}
{"deck_name":"CS356_Unit15_Superscalar","slide_number":42,"chunk_index":0,"title":"ROB: Operation","summary":"ROB: Operation slide explaining Details tail allocation, result buffering, head commit, and flushing younger instructions on misprediction/exception.","main_text":"ROB tail entry allocated for each issued instruction, keeping program order. Completed results are forwarded and stored in ROB until reaching head. Only fully completed head instructions commit. On exception/misprediction, flush everyone behind the faulting branch/instruction and restart on correct path.","notes_text":"","keywords":["rob","tail","head","commit","flush","misprediction","exception"],"images":[],"layout":{"num_text_boxes":2,"num_images":0,"dominant_visual_type":"text-heavy"},"metadata":{"course":"CS356","unit":15,"topic":"Speculative Execution and Reorder Buffer","importance_score":8,"file_hash":"832bcbf6416184b2c4bb4720eed39d5860057d586681310645ba438e054f42bf"}}
{"deck_name":"CS356_Unit15_Superscalar","slide_number":43,"chunk_index":0,"title":"Speculative Execution (ROB Flushing)","summary":"Speculative Execution (ROB Flushing) slide explaining Shows ROB states for predicted branches and pipeline flush/recovery when a branch is mispredicted.","main_text":"Predict branches and execute most likely path. If mispredicted, simply flush ROB entries after the branch and refill with correct path. Requires good prediction to be worthwhile.","notes_text":"","keywords":["speculative","execution","rob","flush","branch","prediction","recovery"],"images":[{"description":"Diagram or figure related to: Speculative Execution (ROB Flushing)","labels":[],"position":{"x":0.03,"y":0.08,"width":0.94,"height":0.8}}],"layout":{"num_text_boxes":4,"num_images":1,"dominant_visual_type":"mixed"},"metadata":{"course":"CS356","unit":15,"topic":"Speculative Execution and Reorder Buffer","importance_score":8,"file_hash":"832bcbf6416184b2c4bb4720eed39d5860057d586681310645ba438e054f42bf"}}
{"deck_name":"CS356_Unit15_Superscalar","slide_number":44,"chunk_index":0,"title":"Wrong-Path Execution / Exceptions & Mispredictions","summary":"Wrong-Path Execution / Exceptions & Mispredictions slide explaining Connects ROB flushing to handling divide-by-zero/page faults and branch mispredictions safely.","main_text":"ROB allows throwing away younger instructions after an exception (e.g., DIV by zero, ST page fault) and replaying them. For speculative execution, ROB enables discarding wrong-path results after a mispredicted JEQ.","notes_text":"","keywords":["wrong-path","exceptions","mispredictions","rob","replay","discard"],"images":[{"description":"Diagram or figure related to: Wrong-Path Execution / Exceptions & Mispredictions","labels":[],"position":{"x":0.05,"y":0.13,"width":0.9,"height":0.72}}],"layout":{"num_text_boxes":5,"num_images":1,"dominant_visual_type":"mixed"},"metadata":{"course":"CS356","unit":15,"topic":"Speculative Execution and Reorder Buffer","importance_score":8,"file_hash":"832bcbf6416184b2c4bb4720eed39d5860057d586681310645ba438e054f42bf"}}
{"deck_name":"CS356_Unit15_Superscalar","slide_number":45,"chunk_index":0,"title":"Case 1: Correctly Predicted Branch","summary":"Case 1: Correctly Predicted Branch slide explaining Shows normal ROB/queue commit when JEQ prediction is correct and younger ops can retire in order once ready.","main_text":"If the JEQ is correctly predicted, normal execution proceeds and instructions after the JEQ can commit when ready. Functional unit queues and ROB manage out-of-order completion with in-order retirement.","notes_text":"","keywords":["case","correctly","predicted","branch","jeq","rob","commit"],"images":[{"description":"Diagram or figure related to: Case 1: Correctly Predicted Branch","labels":[],"position":{"x":0.04,"y":0.1,"width":0.92,"height":0.78}}],"layout":{"num_text_boxes":6,"num_images":1,"dominant_visual_type":"mixed"},"metadata":{"course":"CS356","unit":15,"topic":"Speculative Execution and Reorder Buffer","importance_score":7,"file_hash":"832bcbf6416184b2c4bb4720eed39d5860057d586681310645ba438e054f42bf"}}
{"deck_name":"CS356_Unit15_Superscalar","slide_number":46,"chunk_index":0,"title":"Case 2: Mispredicted Branch","summary":"Case 2: Mispredicted Branch slide explaining Shows that when JEQ is wrong, younger ROB and queue entries are flushed and execution restarts at correct target.","main_text":"If the JEQ is mispredicted, all later (younger) instructions in the ROB and functional unit queues are flushed. Then fetch and execution resume at the correct target basic block.","notes_text":"","keywords":["case","mispredicted","branch","flush","rob","resume","target"],"images":[{"description":"Diagram or figure related to: Case 2: Mispredicted Branch","labels":[],"position":{"x":0.04,"y":0.1,"width":0.92,"height":0.78}}],"layout":{"num_text_boxes":6,"num_images":1,"dominant_visual_type":"mixed"},"metadata":{"course":"CS356","unit":15,"topic":"Speculative Execution and Reorder Buffer","importance_score":7,"file_hash":"832bcbf6416184b2c4bb4720eed39d5860057d586681310645ba438e054f42bf"}}
{"deck_name":"CS356_Unit15_Superscalar","slide_number":47,"chunk_index":0,"title":"Attacks to Out-of-Order Execution","summary":"Attacks to Out-of-Order Execution slide explaining Introduces Meltdown and Spectre as vulnerabilities caused by speculative execution and cache side effects.","main_text":"Meltdown & Spectre Meltdown allows a program to access memory/secrets of other programs and OS by exploiting out-of-order execution before permission checks. Spectre tricks correct programs into speculatively accessing secret-dependent array indices, leaving cache traces. Both exploit that speculation/caching effects are not undone.","notes_text":"","keywords":["attacks","out-of-order","meltdown","spectre","speculation","cache","side-channel"],"images":[],"layout":{"num_text_boxes":2,"num_images":0,"dominant_visual_type":"text-heavy"},"metadata":{"course":"CS356","unit":15,"topic":"Security Attacks on Speculation","importance_score":7,"file_hash":"832bcbf6416184b2c4bb4720eed39d5860057d586681310645ba438e054f42bf"}}
{"deck_name":"CS356_Unit15_Superscalar","slide_number":48,"chunk_index":0,"title":"Meltdown Idea","summary":"Meltdown Idea slide explaining Step-by-step attack using exception delay plus cache probing to infer kernel data via timing of a shared probe array.","main_text":"Start processes A and B sharing probe array (4096*256 bytes). A flushes cache. B triggers exception (slow handler) then speculatively reads secret kernel data and uses it to index probe array. After B dies, A reads all pages; the fastest page reveals the secret index. Code sketch uses clflush, access_kernel_mem, and timing reads.","notes_text":"","keywords":["meltdown","exception","cache","probe","array","timing","kernel","secret"],"images":[],"layout":{"num_text_boxes":2,"num_images":0,"dominant_visual_type":"text-heavy"},"metadata":{"course":"CS356","unit":15,"topic":"Security Attacks on Speculation","importance_score":7,"file_hash":"832bcbf6416184b2c4bb4720eed39d5860057d586681310645ba438e054f42bf"}}
{"deck_name":"CS356_Unit15_Superscalar","slide_number":49,"chunk_index":0,"title":"Spectre Idea","summary":"Spectre Idea slide explaining Describes speculative bounds-check bypass to read arbitrary in-process data and leak it through cache timing on array2.","main_text":"Evict array2 from cache. Train branch predictor with x < array1_size. Then use x > array1_size to speculatively read arbitrary data via array1, and access array2 at secret-dependent offset. After rollback, cache state remains. Measure array2 access times to exfiltrate secret.","notes_text":"","keywords":["spectre","branch","predictor","speculative","bounds","bypass","cache","timing"],"images":[],"layout":{"num_text_boxes":2,"num_images":0,"dominant_visual_type":"text-heavy"},"metadata":{"course":"CS356","unit":15,"topic":"Security Attacks on Speculation","importance_score":7,"file_hash":"832bcbf6416184b2c4bb4720eed39d5860057d586681310645ba438e054f42bf"}}
{"deck_name":"CS356_Unit15_Superscalar","slide_number":50,"chunk_index":0,"title":"Conclusions","summary":"Conclusions slide explaining Summarizes root design issues enabling attacks and common mitigations with performance costs.","main_text":"Exploited CPU design issues: ROB does not undo cache fills; permission bits checked after speculation (Meltdown). Solutions: OS patches and hardware mitigations can cost up to ~25% performance; isolate browser tabs into separate processes; reduce JS timing resolution.","notes_text":"","keywords":["conclusions","rob","cache","permissions","mitigations","performance"],"images":[],"layout":{"num_text_boxes":1,"num_images":0,"dominant_visual_type":"text-heavy"},"metadata":{"course":"CS356","unit":15,"topic":"Summary / Conclusions","importance_score":6,"file_hash":"832bcbf6416184b2c4bb4720eed39d5860057d586681310645ba438e054f42bf"}}
{"deck_name":"CS356_Unit15_Superscalar","slide_number":51,"chunk_index":0,"title":"Final Example #1","summary":"Final Example #1 slide explaining Practice problem about stalls/execution ordering when a DIV takes >16 cycles and writes to %rdx:%rax.","main_text":"Assume the first div instruction requires > 16 cycles to execute. Indicate which instructions will be able to execute and which will also stall. Recall divide instruction puts results in %rdx:%rax.","notes_text":"","keywords":["final","example","div","stall","ordering","rdx","rax"],"images":[],"layout":{"num_text_boxes":1,"num_images":0,"dominant_visual_type":"text-heavy"},"metadata":{"course":"CS356","unit":15,"topic":"Dynamic Scheduling / Out-of-Order Execution","importance_score":5,"file_hash":"832bcbf6416184b2c4bb4720eed39d5860057d586681310645ba438e054f42bf"}}
{"deck_name":"CS356_Unit15_Superscalar","slide_number":52,"chunk_index":0,"title":"Final Example #2","summary":"Final Example #2 slide explaining Practice problem about which instructions proceed under a 100-cycle load miss in all cache levels.","main_text":"Assume the first load instruction misses in all levels of cache and will take at least 100 cycles to retrieve the desired data from memory. Indicate which instructions will be able to execute and which will also stall.","notes_text":"","keywords":["final","example","load","miss","cache","stall","ordering"],"images":[],"layout":{"num_text_boxes":1,"num_images":0,"dominant_visual_type":"text-heavy"},"metadata":{"course":"CS356","unit":15,"topic":"Dynamic Scheduling / Out-of-Order Execution","importance_score":5,"file_hash":"832bcbf6416184b2c4bb4720eed39d5860057d586681310645ba438e054f42bf"}}
{"deck_name":"CS356_Unit15_Superscalar","slide_number":53,"chunk_index":0,"title":"Control Dependencies","summary":"Control Dependencies slide explaining Defines basic blocks and illustrates control limits on ILP with a branch-terminated sequence.","main_text":"This is a basic block (starts with target, ends with branch): ld 0(%r8),%r9 and %r10,%r11 L1: add %r8,%r12 or %r11,%r13 sub %r14,%r10 jeq %r12,%r14,L1 xor %r10,%r15.","notes_text":"","keywords":["control","dependencies","basic","block","branch","ilp"],"images":[],"layout":{"num_text_boxes":2,"num_images":0,"dominant_visual_type":"text-heavy"},"metadata":{"course":"CS356","unit":15,"topic":"Speculative Execution and Reorder Buffer","importance_score":6,"file_hash":"832bcbf6416184b2c4bb4720eed39d5860057d586681310645ba438e054f42bf"}}
{"deck_name":"CS356_Unit15_Superscalar","slide_number":54,"chunk_index":0,"title":"Speculative Path vs Correct Path","summary":"Speculative Path vs Correct Path slide explaining Visual comparison of ROB filling along predicted path, flushing on mispredict, and refilling on correct basic blocks.","main_text":"Graphical depiction contrasting speculative path and correct path across multiple basic blocks, showing times of prediction, misprediction discovery, flush, and recovery.","notes_text":"","keywords":["speculative","path","correct","path","flush","recovery","basic","blocks"],"images":[{"description":"Diagram or figure related to: Speculative Path vs Correct Path","labels":[],"position":{"x":0.02,"y":0.05,"width":0.96,"height":0.86}}],"layout":{"num_text_boxes":2,"num_images":1,"dominant_visual_type":"mixed"},"metadata":{"course":"CS356","unit":15,"topic":"Speculative Execution and Reorder Buffer","importance_score":7,"file_hash":"832bcbf6416184b2c4bb4720eed39d5860057d586681310645ba438e054f42bf"}}
{"deck_name":"CS356_Unit15_Superscalar","slide_number":55,"chunk_index":0,"title":"Correct Path Resume Example","summary":"Correct Path Resume Example slide explaining Microexample showing resume at L1 after mispredicted JEQ, with DIV/ADD/LD on the correct target.","main_text":"After flushing younger instructions behind JEQ, fetch and execution resume at L1: div %r10; add %rdx,%r10; ld %r14,0(%r13). Shows correct-path continuation after rollback.","notes_text":"","keywords":["resume","correct","path","jeq","flush","rollback","div","add","ld"],"images":[{"description":"Diagram or figure related to: Correct Path Resume Example","labels":[],"position":{"x":0.06,"y":0.18,"width":0.88,"height":0.6}}],"layout":{"num_text_boxes":4,"num_images":1,"dominant_visual_type":"mixed"},"metadata":{"course":"CS356","unit":15,"topic":"Speculative Execution and Reorder Buffer","importance_score":7,"file_hash":"832bcbf6416184b2c4bb4720eed39d5860057d586681310645ba438e054f42bf"}}
{"deck_name":"CS356_Unit15_Superscalar","slide_number":56,"chunk_index":0,"title":"End / Transition","summary":"End / Transition slide explaining Closing slide signaling end of unit content.","main_text":"","notes_text":"","keywords":["end","transition"],"images":[],"layout":{"num_text_boxes":0,"num_images":0,"dominant_visual_type":"text-heavy"},"metadata":{"course":"CS356","unit":15,"topic":"Superscalar CPUs","importance_score":5,"file_hash":"832bcbf6416184b2c4bb4720eed39d5860057d586681310645ba438e054f42bf"}}
