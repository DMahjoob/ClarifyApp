{"deck_name":"CS356_Unit12_HeapManagement","slide_number":1,"chunk_index":0,"title":"Unit 12: Heap Management Overview","summary":"Introduces heap management in CS356, focusing on allocators, smart pointers, and garbage collection, and why heap behavior matters for program correctness and performance.","main_text":"This unit covers how dynamic memory on the heap is managed, contrasting manual allocators with automated garbage collection. The lecture frames three major themes: (1) explicit heap allocation/deallocation via library allocators such as malloc/free (or new/delete), (2) allocator design challenges like fragmentation, free-block tracking, and placement policies, and (3) implicit deallocation via garbage collection, including reference counting and tracing collectors. Students should understand the tradeoffs between control and safety: manual allocation enables predictable performance but risks dangling pointers and leaks, while GC reduces programmer burden but introduces runtime overhead and pause behavior. The rest of the deck builds from memory layout fundamentals to concrete allocator mechanisms and finally to GC strategies used in modern languages.","notes_text":"Goal: connect low-level allocator mechanisms to high-level language memory models and to MallocLab implementation choices.","keywords":["heap management","allocators","malloc","free","new/delete","garbage collection","smart pointers","fragmentation","CS356","dynamic memory"],"images":[],"layout":{"num_text_boxes":1,"num_images":0,"dominant_visual_type":"text-heavy"},"metadata":{"course":"CS356","unit":12,"topic":"Heap Management Overview","importance_score":7,"file_hash":"sha256_placeholder"}}
{"deck_name":"CS356_Unit12_HeapManagement","slide_number":2,"chunk_index":0,"title":"Stack vs Heap","summary":"Explains how stack memory differs from heap memory in purpose, lifetime, performance, and limitations.","main_text":"The stack is used by the function call mechanism. Each active function call in a thread has a stack frame that stores local variables. Stack allocation and deallocation are extremely fast because they typically only adjust the stack pointer register (e.g., %rsp). When a function returns, its locals are automatically deallocated, which is convenient but means the data disappears—functions must not return pointers to stack data. The stack is size-limited by the OS (e.g., ~8MB per thread on Linux), so deep recursion or large locals can cause stack overflow.\n\nThe heap is used for long-lived or large data shared across functions and threads. The OS provides a heap region for the entire process, allowing large allocations and lifetimes that extend beyond a function return. Heap memory must be explicitly reused and deallocated when no longer needed. Unlike the stack, heap allocation has overhead because the allocator must track free blocks and manage fragmentation.","notes_text":"Key exam point: lifetime + ownership. Stack is automatic and scoped; heap is manual/shared and can outlive callers.","keywords":["stack","heap","stack frame","automatic deallocation","long-lived objects","stack overflow","heap overhead","sharing","lifetime"],"images":[{"description":"Memory layout diagram showing code/data, heap growing upward, and stack growing downward in virtual address space.","labels":[".text",".data",".bss","heap","stack","memory-mapped regions","brk"],"position":{"x":0.0,"y":0.0,"width":1.0,"height":1.0}}],"layout":{"num_text_boxes":2,"num_images":1,"dominant_visual_type":"mixed"},"metadata":{"course":"CS356","unit":12,"topic":"Memory Regions: Stack and Heap","importance_score":9,"file_hash":"sha256_placeholder"}}
{"deck_name":"CS356_Unit12_HeapManagement","slide_number":3,"chunk_index":0,"title":"Heap Management: Explicit vs Implicit Deallocation","summary":"Contrasts manual freeing of heap blocks with garbage collection and highlights typical bugs.","main_text":"Heap memory can be reclaimed in two ways. With explicit deallocation, programmers manually free heap blocks—free() in C, delete in C++. This provides control but creates two classic failure modes. First, dangling pointers occur if a block is freed while still referenced elsewhere, leading to use-after-free bugs. Second, memory leaks occur if a block is never freed, permanently reducing available heap space.\n\nWith implicit deallocation (garbage collection), the runtime automatically detects and frees blocks that are no longer in use. Detection can be done by reference counting or by exploring the object graph to find unreachable objects. GC reduces dangling pointer risk but leaks are still possible if references to unneeded objects remain. A C example illustrates explicit allocation and freeing: a function mallocs an array of Points, uses it, and must free it once no longer needed.","notes_text":"Remember: GC solves many safety issues but not logical leaks (keeping references).","keywords":["explicit deallocation","implicit deallocation","garbage collection","dangling pointer","memory leak","free","delete","reference counting"],"images":[],"layout":{"num_text_boxes":2,"num_images":0,"dominant_visual_type":"text-heavy"},"metadata":{"course":"CS356","unit":12,"topic":"Explicit vs Garbage-Collected Heap","importance_score":8,"file_hash":"sha256_placeholder"}}
{"deck_name":"CS356_Unit12_HeapManagement","slide_number":4,"chunk_index":0,"title":"Extending the Heap with sbrk","summary":"Shows how allocators request more heap space from the OS when free space is insufficient.","main_text":"When the heap lacks space to satisfy an allocation, the allocator must extend it by requesting more memory from the OS. In Linux, a traditional interface is sbrk(intptr_t increment), which moves the program break (brk) pointer up or down and returns the old brk on success. If increment > 0, the heap grows upward and the returned address is where the new heap region starts. sbrk(0) returns the current heap end. Newly obtained memory is zero-initialized.\n\nA process memory map places code (.text), initialized data (.data), uninitialized data (.bss), the heap, memory-mapped regions (e.g., shared libraries), and the user stack in distinct virtual ranges. The heap starts near a low address and grows upward toward higher addresses, while the stack grows downward. Understanding brk movement is essential for implementing custom allocators and for diagnosing allocation failures.","notes_text":"Modern allocators may also use mmap for large requests, but sbrk explains the core model.","keywords":["sbrk","brk pointer","heap extension","program break","virtual address space","memory map","Linux heap"],"images":[{"description":"Virtual memory layout figure labeling text/data/bss/heap/brk/mmap regions and user stack.","labels":["brk","heap","stack","mmap","0x10000000","0x80000000"],"position":{"x":0.0,"y":0.0,"width":1.0,"height":1.0}}],"layout":{"num_text_boxes":2,"num_images":1,"dominant_visual_type":"diagram"},"metadata":{"course":"CS356","unit":12,"topic":"Heap Growth and OS Interface","importance_score":8,"file_hash":"sha256_placeholder"}}
{"deck_name":"CS356_Unit12_HeapManagement","slide_number":5,"chunk_index":0,"title":"Libc Allocator API and Example","summary":"Defines malloc/calloc/free semantics and illustrates stack vs heap addresses with a runtime example.","main_text":"Libc exposes the standard heap allocator interface. malloc(size) allocates size bytes and returns a pointer to the start of a usable payload region. calloc(nmemb, size) allocates nmemb*size bytes and initializes the payload to zero. free(ptr) releases a block previously returned by malloc/calloc, returning it to the allocator’s pool for reuse; ptr must be exactly the pointer originally returned.\n\nAn example program reads a runtime-known number of students into a stack variable num, then allocates an int array scores on the heap of length num. The diagram emphasizes that stack variables reside in the user stack region, while heap blocks occupy addresses in the heap region; malloc returns the payload pointer. Correctness requires calling free(scores) when finished. The example also motivates why heap blocks cannot be relocated easily: programs store and use their addresses directly.","notes_text":"calloc is just malloc + memset(0) from a client perspective.","keywords":["malloc","calloc","free","payload pointer","heap addresses","stack variable","runtime-sized array"],"images":[{"description":"Diagram showing stack frame with num/scores pointer and heap array scores[0..n-1] addresses.","labels":["scores","num","stack frame","heap"],"position":{"x":0.0,"y":0.0,"width":1.0,"height":1.0}}],"layout":{"num_text_boxes":2,"num_images":1,"dominant_visual_type":"mixed"},"metadata":{"course":"CS356","unit":12,"topic":"Allocator API","importance_score":9,"file_hash":"sha256_placeholder"}}
{"deck_name":"CS356_Unit12_HeapManagement","slide_number":6,"chunk_index":0,"title":"Allocator Requirements and Performance Goals","summary":"Lists constraints on heap allocators and defines throughput/utilization metrics.","main_text":"An allocator must handle an arbitrary interleaving of malloc/free requests and respond immediately—it cannot delay allocations to optimize globally. It can only use heap space (not stack/globals) for its metadata, and it cannot move already allocated blocks because user code holds pointers to their addresses. All blocks must be aligned to 8 or 16 bytes to preserve struct alignment on 64-bit systems.\n\nPerformance goals emphasize high throughput (many malloc/free operations per second) and high memory utilization. Utilization measures how much of the allocated heap is actually in use rather than trapped in unusable fragments. Peak utilization after k operations is U(k) = max{P(i)}/H(k), where P(i) is heap memory currently allocated (not freed) after i requests, and H(k) is total heap size obtained from the OS after k requests. Fragmentation is the main enemy of utilization.","notes_text":"These goals trade off: faster placement may worsen fragmentation, hurting utilization.","keywords":["allocator requirements","alignment","no moving blocks","throughput","utilization","peak memory utilization","P(i)","H(k)"],"images":[],"layout":{"num_text_boxes":2,"num_images":0,"dominant_visual_type":"text-heavy"},"metadata":{"course":"CS356","unit":12,"topic":"Allocator Design Constraints","importance_score":8,"file_hash":"sha256_placeholder"}}
{"deck_name":"CS356_Unit12_HeapManagement","slide_number":7,"chunk_index":0,"title":"Fragmentation: External vs Internal","summary":"Defines fragmentation types and why they reduce effective heap capacity.","main_text":"Fragmentation occurs when free heap memory exists but cannot be used effectively. External fragmentation arises when there are many small free gaps between allocated blocks. Even if total free memory is large, a request may fail because no single contiguous free block is big enough. Internal fragmentation happens when the allocator gives a block larger than the payload the user requested, so unused bytes inside allocated blocks are wasted. Internal fragmentation is common with fixed-size chunk allocators or when rounding payloads up for alignment.\n\nAllocator strategies such as coalescing adjacent free blocks combat external fragmentation, while careful block sizing and splitting help reduce internal fragmentation. Since allocated blocks cannot be moved, fragmentation accumulates over time in long-running programs, making management policies crucial to sustaining high utilization.","notes_text":"Think of external as ‘between blocks’ and internal as ‘within blocks’.","keywords":["fragmentation","external fragmentation","internal fragmentation","contiguous free memory","alignment waste","heap utilization"],"images":[{"description":"Illustrations showing scattered free gaps (external) and oversized allocated blocks with unused interior (internal).","labels":["allocated","free"],"position":{"x":0.0,"y":0.0,"width":1.0,"height":1.0}}],"layout":{"num_text_boxes":1,"num_images":1,"dominant_visual_type":"diagram"},"metadata":{"course":"CS356","unit":12,"topic":"Fragmentation","importance_score":9,"file_hash":"sha256_placeholder"}}
{"deck_name":"CS356_Unit12_HeapManagement","slide_number":8,"chunk_index":0,"title":"Implementation Issues in Heap Allocators","summary":"Outlines core allocator subproblems: tracking free blocks, placement, splitting, and coalescing.","main_text":"Implementing a heap allocator requires solving several related subproblems. First, free block management: the allocator must track which heap regions are free vs allocated to enable reuse. Second, placement algorithms: when a request arrives, the allocator must choose which free block to allocate (e.g., first-fit, next-fit, best-fit). Third, splitting: if a chosen free block is larger than needed, the allocator may split it into an allocated block plus a smaller free remainder. Fourth, coalescing: when blocks are freed, adjacent free blocks should be merged to reduce external fragmentation. Each feature introduces metadata overhead and affects throughput and utilization.\n\nThe lecture uses these issues as a roadmap for the remaining allocator designs, starting with implicit lists, then explicit lists, then segregated lists.","notes_text":"MallocLab asks you to implement find_fit, place, mm_malloc, and coalesce correctly.","keywords":["free block management","placement algorithm","first-fit","best-fit","splitting","coalescing","allocator metadata"],"images":[],"layout":{"num_text_boxes":1,"num_images":0,"dominant_visual_type":"text-heavy"},"metadata":{"course":"CS356","unit":12,"topic":"Allocator Components","importance_score":7,"file_hash":"sha256_placeholder"}}
{"deck_name":"CS356_Unit12_HeapManagement","slide_number":9,"chunk_index":0,"title":"Implicit vs Explicit Free Lists","summary":"Compares scanning-based implicit lists to pointer-based explicit free lists.","main_text":"Allocated blocks are owned by the programmer and do not need explicit tracking. Instead, allocators manage free blocks. With an implicit free list, all blocks (allocated + free) are laid out in a linear sequence in the heap. To satisfy malloc, the allocator scans through the sequence, checking each block’s header to find a suitable free block. This is simple but can be slow because allocated blocks are also scanned.\n\nWith an explicit free list, the allocator maintains a separate linked list containing only free blocks. Each free block stores pointers to the next (and possibly previous) free block, allowing faster searches because allocated blocks are skipped. The tradeoff is additional metadata inside free blocks and more complex insertion/removal logic.","notes_text":"Implicit lists are baseline; explicit lists improve throughput at some utilization cost.","keywords":["implicit free list","explicit free list","linear scan","free list pointers","metadata overhead"],"images":[{"description":"Side-by-side heap diagrams: implicit list scanning all blocks; explicit list linking only free blocks.","labels":["header","allocated/free bit","free_list","next ptr"],"position":{"x":0.0,"y":0.0,"width":1.0,"height":1.0}}],"layout":{"num_text_boxes":2,"num_images":1,"dominant_visual_type":"comparison"},"metadata":{"course":"CS356","unit":12,"topic":"Free List Structures","importance_score":8,"file_hash":"sha256_placeholder"}}
{"deck_name":"CS356_Unit12_HeapManagement","slide_number":10,"chunk_index":0,"title":"Implicit Free List Block Format and Alignment","summary":"Explains heap block headers, alignment, and epilogue in an implicit list allocator.","main_text":"Implicit free lists require a way to locate block boundaries and allocation status. Blocks are aligned to the largest type—8-byte boundaries on 64-bit systems. The slide uses “word” (4 bytes) and “double word” (8 bytes) terminology. Each block begins with a header storing the block size (a multiple of 8) plus a low-bit flag indicating allocated (1) or free (0). Payloads follow the header and are also aligned. The heap ends with an epilogue header: an always-allocated block of size 0 that marks heap termination.\n\nPointer arithmetic is subtle: adding 1 to a typed pointer advances by sizeof(type), so allocator helper functions must compute next/prev headers carefully. A suggested debugging loop iterates from the first block header while mm_block_size(b) != 0, printing sizes and allocation bits to verify list integrity.","notes_text":"Block size includes header/footer; payload size is block size minus overhead.","keywords":["block header","allocated bit","alignment","double word","epilogue block","pointer arithmetic","implicit list"],"images":[{"description":"Block layout diagram showing header, payload, padding, and size/allocated-bit encoding.","labels":["header","payload","padding","size","allocated bit"],"position":{"x":0.0,"y":0.0,"width":1.0,"height":1.0}}],"layout":{"num_text_boxes":2,"num_images":1,"dominant_visual_type":"diagram"},"metadata":{"course":"CS356","unit":12,"topic":"Implicit List Mechanics","importance_score":9,"file_hash":"sha256_placeholder"}}
{"deck_name":"CS356_Unit12_HeapManagement","slide_number":11,"chunk_index":0,"title":"Coalescing Motivation and Boundary Tags","summary":"Shows why footers enable constant-time coalescing of adjacent free blocks.","main_text":"When a block is freed, the allocator may want to merge it with adjacent free blocks to reduce external fragmentation. Without extra metadata, a freed block’s header provides no direct way to find the previous block; determining whether the previous block is free would require scanning from heap start, costing O(n).\n\nBoundary tags solve this by adding a footer to each block. The footer is a copy of the header placed at the end of the block, immediately before the next block’s header. When freeing a block, the allocator can read the previous block’s footer to learn its size and allocation status, compute the previous header’s address in O(1), and coalesce if needed. This enables fast, local coalescing during free operations.","notes_text":"Boundary tags are required for segregated fit too.","keywords":["coalescing","boundary tags","footer","previous block","O(1) coalescing","free operation"],"images":[{"description":"Heap sequence illustrating headers and footers (boundary tags) and how freeing triggers merge.","labels":["footer","header","free","allocated"],"position":{"x":0.0,"y":0.0,"width":1.0,"height":1.0}}],"layout":{"num_text_boxes":2,"num_images":1,"dominant_visual_type":"diagram"},"metadata":{"course":"CS356","unit":12,"topic":"Coalescing with Footers","importance_score":9,"file_hash":"sha256_placeholder"}}
{"deck_name":"CS356_Unit12_HeapManagement","slide_number":12,"chunk_index":0,"title":"Coalescing Procedure, Timing, and Cases","summary":"Details steps for coalescing, when to do it, and the four possible neighbor cases.","main_text":"To coalesce a freed block, the allocator starts from the payload pointer passed to free, steps back one word to the block header, and obtains its size. It then checks the footer of the previous block (one word before the header) to see if that block is free; if so, it computes the previous header address using the previous size and merges the blocks by updating header and footer sizes. It also checks the next block’s header to see if the next block is free.\n\nCoalescing may be immediate (done on every free) or deferred (done later when searching for space). Immediate coalescing is simpler but can waste work if blocks would be reallocated soon. With immediate coalescing there are four neighbor cases: (1) prev alloc, next alloc; (2) prev alloc, next free; (3) prev free, next alloc; (4) prev free, next free. Each case updates sizes and free-list links accordingly.","notes_text":"MallocLab typically uses immediate coalescing with these four cases.","keywords":["coalescing cases","immediate vs deferred","prev_alloc","next_alloc","header/footer update","free"],"images":[{"description":"Step-numbered coalescing example showing merge of adjacent free blocks into a larger free block.","labels":["case 1-4","prev","next","free"],"position":{"x":0.0,"y":0.0,"width":1.0,"height":1.0}}],"layout":{"num_text_boxes":2,"num_images":1,"dominant_visual_type":"mixed"},"metadata":{"course":"CS356","unit":12,"topic":"Coalescing Logic","importance_score":10,"file_hash":"sha256_placeholder"}}
{"deck_name":"CS356_Unit12_HeapManagement","slide_number":13,"chunk_index":0,"title":"Placement Algorithms: First/Next/Best Fit","summary":"Defines three classic policies for choosing a free block and their tradeoffs.","main_text":"Placement algorithms decide which free block to allocate for a request. First fit scans from the beginning of the heap on each malloc and chooses the first free block large enough. It is fast on average but may leave small fragments near the front, increasing external fragmentation. Next fit continues scanning from where the last allocation ended, reducing repeated work in the front of the heap but sometimes worsening fragmentation patterns. Best fit searches the entire free list to find the smallest free block that satisfies the request, which tends to reduce leftover space and fragmentation but increases search time.\n\nMallocLab’s find_fit(size) function is where these policies are implemented. The choice affects throughput and utilization: faster scans raise throughput, while more selective fits can improve utilization.","notes_text":"Best fit approximations appear later in segregated fit.","keywords":["placement algorithm","first fit","next fit","best fit","find_fit","tradeoff throughput/utilization"],"images":[{"description":"Three heap illustrations showing how first/next/best fit pick different free blocks for alloc(4) and alloc(2).","labels":["First Fit","Next Fit","Best Fit"],"position":{"x":0.0,"y":0.0,"width":1.0,"height":1.0}}],"layout":{"num_text_boxes":2,"num_images":1,"dominant_visual_type":"comparison"},"metadata":{"course":"CS356","unit":12,"topic":"Placement Policies","importance_score":8,"file_hash":"sha256_placeholder"}}
{"deck_name":"CS356_Unit12_HeapManagement","slide_number":14,"chunk_index":0,"title":"Splitting and mm_malloc Integration","summary":"Shows how allocators split oversized blocks and combine find_fit/place in mm_malloc.","main_text":"A free block chosen by a placement policy may be larger than required. If the leftover portion after satisfying the request is large enough to form a valid free block (with its own header/footer and minimum payload), the allocator splits it. Example: malloc(12) requires header + footer overhead and rounds payload up to the next multiple of 8, yielding a required block size of 24 bytes. If a 40-byte free block is selected, it can be split into a 24-byte allocated block and a 16-byte free block.\n\nMallocLab’s place(bp, size) handles splitting and returns the allocated block header. mm_malloc(size) computes required_block_size, calls find_fit; if none is found, it extends the heap; then it calls place and returns a payload pointer. Correct splitting reduces internal fragmentation while enabling reuse of the remaining free space.","notes_text":"Remember minimum free block size must hold header/footer and free pointers if explicit lists are used.","keywords":["splitting","place","mm_malloc","required_block_size","payload rounding","internal fragmentation"],"images":[{"description":"Before/after splitting diagram showing a large free block divided into allocated + smaller free block.","labels":["allocated","free","24","16","40"],"position":{"x":0.0,"y":0.0,"width":1.0,"height":1.0}}],"layout":{"num_text_boxes":2,"num_images":1,"dominant_visual_type":"diagram"},"metadata":{"course":"CS356","unit":12,"topic":"Splitting and Allocation Flow","importance_score":9,"file_hash":"sha256_placeholder"}}
{"deck_name":"CS356_Unit12_HeapManagement","slide_number":15,"chunk_index":0,"title":"Explicit Free Lists","summary":"Introduces storing next/prev pointers inside free blocks and flexible ordering of free lists.","main_text":"Explicit free lists store linking pointers directly inside free blocks. When a block is free, part of its payload area is repurposed to hold pointers to other free blocks, typically forming a doubly-linked list. This speeds up allocation searches because only free blocks are traversed. The tradeoff is that free blocks must be large enough to contain the pointers plus header/footer, increasing the minimum block size and possibly internal fragmentation for tiny allocations.\n\nFree blocks can be inserted into the list in any order. If coalescing is deferred, the free list may contain multiple blocks out of address order (e.g., blocks 3, 1, 4). Alternatives include maintaining lists sorted by address (simplifies coalescing) or by size (approximates best fit).","notes_text":"Insertion/removal correctness is the main complexity in explicit list MallocLab variants.","keywords":["explicit free list","doubly linked list","prev/next free block","minimum block size","free list ordering"],"images":[{"description":"Example heap showing how freeing blocks updates an explicit free list with prev/next pointers.","labels":["Prev Free Blk","Next Free Blk","free_list"],"position":{"x":0.0,"y":0.0,"width":1.0,"height":1.0}}],"layout":{"num_text_boxes":2,"num_images":1,"dominant_visual_type":"diagram"},"metadata":{"course":"CS356","unit":12,"topic":"Explicit Free List Allocators","importance_score":8,"file_hash":"sha256_placeholder"}}
{"deck_name":"CS356_Unit12_HeapManagement","slide_number":16,"chunk_index":0,"title":"Segregated Free Lists: High-Level Idea","summary":"Presents segregated lists as multiple free lists partitioned by block size.","main_text":"Segregated free lists improve search efficiency by maintaining several separate free lists, each responsible for a size class of free blocks. On allocation, the allocator chooses the appropriate size class based on the request and searches only within that class; if none is found, it may consult larger classes. Two main variants are introduced: segregated storage and segregated fit. Both aim to combine higher throughput (shorter searches) with good utilization (better-matched blocks), compared to a single global explicit list.\n\nThe subsequent slides detail how fixed-size chunk lists (segregated storage) eliminate headers and coalescing at the cost of internal fragmentation, while variable-size classed lists (segregated fit) retain boundary tags and coalescing to reduce external fragmentation.","notes_text":"Conceptually: ‘bins’ by size.","keywords":["segregated free lists","size classes","bins","segregated storage","segregated fit","throughput"],"images":[{"description":"Diagram showing multiple free lists (free16, free32, free64, free4k) mapped to size ranges.","labels":["free16","free32","free64","free4k"],"position":{"x":0.0,"y":0.0,"width":1.0,"height":1.0}}],"layout":{"num_text_boxes":2,"num_images":1,"dominant_visual_type":"diagram"},"metadata":{"course":"CS356","unit":12,"topic":"Segregated Lists","importance_score":8,"file_hash":"sha256_placeholder"}}
{"deck_name":"CS356_Unit12_HeapManagement","slide_number":17,"chunk_index":0,"title":"Segregated Storage","summary":"Explains fixed-size chunk free lists and how allocation/free work in this scheme.","main_text":"Segregated storage breaks the heap into multiple lists of fixed-size blocks (chunks). Each list corresponds to one block size, such as 16-byte, 32-byte, 64-byte, or 4KB blocks. On malloc, the allocator selects the smallest fixed size that can hold the requested payload and returns a block from that list. If the list is empty, it extends the heap, splits the new region into blocks of that size, and adds them to the list. On free, the block is returned to its size-appropriate list; list order need not match address order.\n\nBecause all blocks in a list have identical size, headers are unnecessary and coalescing/footers are not used. Metadata overhead is low and lists can be singly linked. The minimum block size is one pointer (for the next free pointer). The downside is internal fragmentation: a request for 33 bytes must use a 64-byte block.","notes_text":"Fast and simple; used for small object allocators and slab allocators.","keywords":["segregated storage","fixed-size blocks","no headers","no coalescing","internal fragmentation","minimum block size"],"images":[{"description":"Heap partition with multiple fixed-size free lists and overlays labeling next pointer and payload.","labels":["next","padding","payload","free16","free32"],"position":{"x":0.0,"y":0.0,"width":1.0,"height":1.0}}],"layout":{"num_text_boxes":2,"num_images":1,"dominant_visual_type":"diagram"},"metadata":{"course":"CS356","unit":12,"topic":"Segregated Storage Allocators","importance_score":8,"file_hash":"sha256_placeholder"}}
{"deck_name":"CS356_Unit12_HeapManagement","slide_number":18,"chunk_index":0,"title":"Segregated Fit","summary":"Describes variable-size classed lists with boundary tags and coalescing.","main_text":"Segregated fit maintains multiple explicit free lists by size ranges, but blocks within a class are variable sized. Because blocks can be split and coalesced, headers and footers (boundary tags) are required. Each list covers a size interval, such as [16–31], [32–63], and ≥64 bytes. A free block placed in list n satisfies n ≤ size < m, where m is the next larger class.\n\nOn initialization, the heap may start as a single large free block in the biggest class. As allocations occur, blocks split and remaining fragments move to smaller classes. If no block exists in the target class, the allocator searches progressively larger classes; if even the largest is empty, it extends the heap. On free, the allocator coalesces with neighbors, removes merged blocks from their lists, and inserts the combined block into the correct size class. This approximates best fit while skipping overly small blocks.","notes_text":"This is the dominant design in high-performance general-purpose allocators.","keywords":["segregated fit","size classes","boundary tags","coalescing","split blocks","approximate best fit"],"images":[{"description":"Before/after example showing malloc from size class lists and coalescing after free(a2).","labels":["free16","free32","free64","ptr1","before/after"],"position":{"x":0.0,"y":0.0,"width":1.0,"height":1.0}}],"layout":{"num_text_boxes":2,"num_images":1,"dominant_visual_type":"mixed"},"metadata":{"course":"CS356","unit":12,"topic":"Segregated Fit Allocators","importance_score":9,"file_hash":"sha256_placeholder"}}
{"deck_name":"CS356_Unit12_HeapManagement","slide_number":19,"chunk_index":0,"title":"Garbage Collection Motivation and Approaches","summary":"Introduces GC as an alternative to manual memory management and previews GC families.","main_text":"Manual heap management is powerful but error-prone. Tools like valgrind can detect leaks, but automated garbage collection aims to reclaim unreachable heap blocks without explicit free calls. Two broad GC approaches are introduced. Reference counting keeps a count of active references per object and frees an object when the count drops to zero. Tracing garbage collectors periodically explore the object graph from a set of roots (globals, static members, and locals in active stack frames) and free any object not reachable from those roots. Tracing can collect cycles, unlike pure reference counting.\n\nGC changes the programming model by shifting responsibility to the runtime, but it adds overhead and can impact latency depending on the collector design. The remaining slides dive into these approaches in detail.","notes_text":"Good framing for languages like Python (RC + cycle GC) vs Java/Go/JS (tracing).","keywords":["garbage collection","valgrind","reference counting","tracing GC","roots","object graph","unreachable objects"],"images":[],"layout":{"num_text_boxes":1,"num_images":0,"dominant_visual_type":"text-heavy"},"metadata":{"course":"CS356","unit":12,"topic":"Garbage Collection Overview","importance_score":8,"file_hash":"sha256_placeholder"}}
{"deck_name":"CS356_Unit12_HeapManagement","slide_number":20,"chunk_index":0,"title":"Reference Counting","summary":"Explains reference counting GC, its basic operations, and its weakness with cycles.","main_text":"In reference counting, each heap object stores a reference count. When a new reference to the object is created, the count increments; when a reference is destroyed or reassigned, the count decrements. If the count reaches zero, the object is deallocated immediately. This may cascade: freeing an object can reduce counts of objects it referenced, potentially freeing them too. Python uses reference counting as a primary GC mechanism, illustrated by getrefcount showing counts increasing with new aliases and decreasing with del.\n\nThe major limitation is cycles. If objects reference each other in a closed loop, their counts never drop to zero even when the cycle is unreachable from program roots. As a result, reference counting alone cannot reclaim cyclic garbage without additional cycle-detection or tracing support.","notes_text":"Reference counting provides prompt reclamation but adds overhead to pointer updates.","keywords":["reference counting","refcount increment/decrement","Python GC","cascade deallocation","cycles","uncollectable garbage"],"images":[],"layout":{"num_text_boxes":2,"num_images":0,"dominant_visual_type":"text-heavy"},"metadata":{"course":"CS356","unit":12,"topic":"Reference Counting GC","importance_score":9,"file_hash":"sha256_placeholder"}}
{"deck_name":"CS356_Unit12_HeapManagement","slide_number":21,"chunk_index":0,"title":"Tracing GC: Mark & Sweep","summary":"Describes mark-and-sweep tracing GC and its tradeoffs.","main_text":"Tracing garbage collectors run when available heap memory is low. The collector identifies roots—global variables, static fields, and locals of active functions—and explores the heap object graph from those roots (often depth-first). In the mark phase, each reachable object is visited and marked via a bit in its header. In the sweep phase, the collector scans all heap objects and frees those not marked.\n\nMark-and-sweep can reclaim cycles because reachability, not reference count, determines liveness. However, it introduces overhead: the sweep checks every object even though only some are reachable. It can also leave memory fragmented because freed objects create holes; a compacting phase may be added to relocate reachable objects and reduce fragmentation. Many systems still require a stop-the-world pause during tracing.","notes_text":"Key contrast: tracing cost is periodic + global; RC cost is incremental + local.","keywords":["tracing GC","mark and sweep","roots","reachable objects","mark bit","sweep phase","compaction","fragmentation"],"images":[{"description":"Mark-and-sweep diagram showing reachable objects from a global root and unreachable objects freed during sweep.","labels":["mark","sweep","global var","reachable bit"],"position":{"x":0.0,"y":0.0,"width":1.0,"height":1.0}}],"layout":{"num_text_boxes":2,"num_images":1,"dominant_visual_type":"flowchart"},"metadata":{"course":"CS356","unit":12,"topic":"Tracing Garbage Collectors","importance_score":9,"file_hash":"sha256_placeholder"}}
{"deck_name":"CS356_Unit12_HeapManagement","slide_number":22,"chunk_index":0,"title":"Stop & Copy and Generational GC","summary":"Explains stop-and-copy tracing and generational hypothesis with Eden/Survivor/Tenured regions.","main_text":"Stop-and-copy tracing addresses fragmentation and sweep overhead by dividing the heap into two equal regions. The program allocates only in the active region. During GC, reachable objects are copied into the inactive region, compacted tightly, and allocation switches to that region. Unreachable objects are never touched, so sweep is avoided. The downside is that long-lived objects are copied repeatedly.\n\nGenerational collectors exploit the weak generational hypothesis: most objects die young. The heap is partitioned into Eden (new objects), two Survivor spaces S0/S1, and a Tenured (Old Gen) region. When Eden fills, live objects are copied to a Survivor space; each GC cycle copies survivors between S0 and S1 and increments a survival counter. Objects that survive many cycles are promoted to Tenured, which is collected less frequently and may use compaction. This reduces copying of old objects while keeping young-gen GC fast.","notes_text":"Java’s collectors are generational; Eden GC pauses are usually small but frequent.","keywords":["stop and copy","generational GC","weak generational hypothesis","Eden","Survivor spaces","S0","S1","Tenured/Old Gen","promotion"],"images":[{"description":"Heap region diagram labeling Eden, S0, S1, and Tenured with copying paths during GC.","labels":["Eden","S0","S1","Tenured","brk"],"position":{"x":0.0,"y":0.0,"width":1.0,"height":1.0}}],"layout":{"num_text_boxes":2,"num_images":1,"dominant_visual_type":"diagram"},"metadata":{"course":"CS356","unit":12,"topic":"Generational Tracing GC","importance_score":10,"file_hash":"sha256_placeholder"}}
{"deck_name":"CS356_Unit12_HeapManagement","slide_number":23,"chunk_index":0,"title":"GC Variations and Remaining Issues","summary":"Summarizes parallel and concurrent collectors and notes that logical leaks can persist under GC.","main_text":"Tracing collectors come in several practical variants. Parallel GC uses multiple threads to explore the object graph, especially in young generations, reducing pause time by leveraging multicore hardware. Concurrent mark-and-sweep performs some marking or sweeping while the program continues running, improving latency. However, it must track concurrent mutations to already-visited objects; some stop-the-world steps remain, such as when Eden fills or when Tenured space requires compaction or promotion.\n\nEven with GC, memory leaks can occur if the program retains references to objects that are no longer semantically needed. Such objects remain reachable from roots and will not be reclaimed. Therefore, GC improves safety but cannot fix poor object-lifecycle logic.","notes_text":"Modern low-pause collectors (e.g., ZGC, Shenandoah) are concurrent + region-based.","keywords":["parallel GC","concurrent mark and sweep","stop-the-world","latency","promotion","GC memory leaks"],"images":[],"layout":{"num_text_boxes":1,"num_images":0,"dominant_visual_type":"text-heavy"},"metadata":{"course":"CS356","unit":12,"topic":"GC Variants and Limitations","importance_score":7,"file_hash":"sha256_placeholder"}}
{"deck_name":"CS356_Unit12_HeapManagement","slide_number":24,"chunk_index":0,"title":"Coalescing Cases (Immediate Coalescing)","summary":"Summarizes the four neighbor-allocation cases an allocator checks when coalescing a newly freed block immediately.","main_text":"With immediate coalescing, the allocator merges a freed block with adjacent free blocks right away to reduce external fragmentation and keep the free structure consistent. Using boundary tags, only four cases matter, based on whether the previous and next physical neighbors are allocated or free. Case 1: prev allocated, next allocated → no coalescing; the freed block becomes a standalone free block. Case 2: prev allocated, next free → merge with the next block; update header/footer to combined size. Case 3: prev free, next allocated → merge with the previous block; update combined size and return pointer to the previous header. Case 4: prev free, next free → merge all three into one larger free block; remove neighboring free blocks from any free lists and write the new size into the outer header/footer. These four cases are enough to guarantee correctness when coalescing is done at free-time.","notes_text":"Boundary tags let you find prev block in O(1), making these checks cheap.","keywords":["coalescing","immediate coalescing","boundary tags","prev/next allocation","four cases","external fragmentation"],"images":[],"layout":{"num_text_boxes":3,"num_images":0,"dominant_visual_type":"text-heavy"},"metadata":{"course":"CS356","unit":12,"topic":"Coalescing Cases","importance_score":9,"file_hash":"sha256_placeholder"}}
{"deck_name":"CS356_Unit12_HeapManagement","slide_number":25,"chunk_index":0,"title":"Coalescing in MallocLab: free_coalesce()","summary":"Shows the structure of the MallocLab coalescing helper and how it returns the correct merged block.","main_text":"The slide provides the MallocLab skeleton for `static BlockHeader *free_coalesce(BlockHeader *bp)`. After a block is freed, this helper reads neighbor allocation bits (prev via footer, next via header), then branches into the four immediate-coalescing cases. Each branch computes the new merged size and rewrites the header/footer tags to reflect the combined free block. If the previous block is free (cases 3 or 4), the function typically returns a pointer to the previous block’s header, because that becomes the start of the merged block. If the previous block is allocated but the next is free (case 2), it returns `bp` after merging with next. This helper is invoked by `mm_free` and also by `extend_heap` to ensure newly created free space is coalesced with neighbors.","notes_text":"Your implementation must also update free-list links if using explicit/segregated lists.","keywords":["free_coalesce","MallocLab","mm_free","extend_heap","header/footer update","neighbor cases"],"images":[],"layout":{"num_text_boxes":3,"num_images":0,"dominant_visual_type":"text-heavy"},"metadata":{"course":"CS356","unit":12,"topic":"Coalescing in MallocLab","importance_score":9,"file_hash":"sha256_placeholder"}}
{"deck_name":"CS356_Unit12_HeapManagement","slide_number":26,"chunk_index":0,"title":"Placement Algorithms: First Fit, Next Fit, Best Fit","summary":"Defines three classic policies for selecting a free block and illustrates how each behaves.","main_text":"Placement policies determine which free block an allocator chooses for a request. **First fit** scans from the heap start each time and picks the first free block that is large enough. It is usually fast, but tends to leave small fragments near the front of the heap, increasing external fragmentation over time. **Next fit** is similar but continues scanning from where the previous search ended, rather than restarting at the heap beginning. This reduces repeated scanning of early blocks but can produce more uneven fragmentation patterns depending on workloads. **Best fit** searches the entire free list or heap to find the smallest free block that satisfies the request, minimizing leftover space and often improving utilization, but at a higher search cost. The diagrams on the slide show that the same allocation requests (e.g., alloc(4), alloc(2)) can land in different places depending on the policy.","notes_text":"In MallocLab, this choice lives in `find_fit`.","keywords":["placement algorithm","first fit","next fit","best fit","find_fit","throughput vs utilization"],"images":[],"layout":{"num_text_boxes":12,"num_images":0,"dominant_visual_type":"comparison"},"metadata":{"course":"CS356","unit":12,"topic":"Placement Algorithms","importance_score":8,"file_hash":"sha256_placeholder"}}
{"deck_name":"CS356_Unit12_HeapManagement","slide_number":27,"chunk_index":0,"title":"Placement in MallocLab: find_fit() Stub","summary":"Gives the `find_fit` skeleton and clarifies what it should return to support allocation.","main_text":"This slide shows the required MallocLab stub for `BlockHeader* find_fit(int size)`. The function must search the allocator’s representation of free space (implicit list, explicit list, or size-class list) to find a free block whose block size is at least the requested `size`. If a suitable block is found, return a pointer to that block (typically its header), enabling `mm_malloc` to call `place` there. If no block fits, return `NULL`, signaling `mm_malloc` to extend the heap. The exact traversal and stopping rule implement your chosen placement policy (first-fit, next-fit, best-fit approximation, etc.), so correctness plus reasonable performance depends heavily on this function.","notes_text":"If you return a payload pointer instead, stay consistent with helper macros.","keywords":["find_fit","MallocLab","placement policy","free block search","return NULL","allocator traversal"],"images":[],"layout":{"num_text_boxes":2,"num_images":0,"dominant_visual_type":"text-heavy"},"metadata":{"course":"CS356","unit":12,"topic":"find_fit","importance_score":8,"file_hash":"sha256_placeholder"}}
{"deck_name":"CS356_Unit12_HeapManagement","slide_number":28,"chunk_index":0,"title":"Splitting During Placement","summary":"Explains how allocators split an oversized free block when placing an allocation.","main_text":"Once a free block is chosen, the allocator checks if it is significantly larger than the required size. If so, it **splits** the block into two: an allocated block of `required_size` and a remaining free block containing the leftover bytes. Splitting is only done when the remainder is large enough to form a valid free block (including header/footer and any minimum payload/pointer space). The slide’s numeric example illustrates a chosen free block being divided so the front portion becomes allocated (allocated bit set), while the tail becomes a smaller free block with its own header/footer tags. Splitting reduces internal fragmentation by avoiding handing out more space than necessary, and it increases future reuse by keeping leftover bytes in the free pool.","notes_text":"Minimum free block size depends on list type (explicit lists need next/prev pointers).","keywords":["splitting","place","required_size","minimum block size","internal fragmentation","header/footer"],"images":[],"layout":{"num_text_boxes":7,"num_images":0,"dominant_visual_type":"diagram"},"metadata":{"course":"CS356","unit":12,"topic":"Splitting During Placement","importance_score":9,"file_hash":"sha256_placeholder"}}
{"deck_name":"CS356_Unit12_HeapManagement","slide_number":29,"chunk_index":0,"title":"Splitting in MallocLab: place() Stub","summary":"Shows the `place` helper skeleton that allocates a block and optionally splits it.","main_text":"The slide provides the MallocLab stub for `static BlockHeader* place(BlockHeader *bp, int size)`. This helper takes a free block `bp` found by `find_fit` and a required block size `size`. It marks `bp` allocated, writes correct header/footer tags, and if `bp` is larger than `size` by at least the minimum free-block size, splits the block: the first part stays allocated, and the remainder becomes a new free block inserted into the free structure. The function then returns a pointer to the allocated block’s header (or payload, depending on your macro convention). Correct splitting logic is essential for utilization and for later coalescing correctness.","notes_text":"Remember to update free-list pointers if you remove/split a free node.","keywords":["place","MallocLab","splitting logic","allocated bit","free remainder","block tags"],"images":[],"layout":{"num_text_boxes":2,"num_images":0,"dominant_visual_type":"text-heavy"},"metadata":{"course":"CS356","unit":12,"topic":"place()","importance_score":8,"file_hash":"sha256_placeholder"}}
{"deck_name":"CS356_Unit12_HeapManagement","slide_number":30,"chunk_index":0,"title":"Putting It Together: mm_malloc() Flow","summary":"Presents the overall allocator pipeline used in `mm_malloc`.","main_text":"`mm_malloc(size_t size)` is the top-level allocation routine. First, it ignores zero-byte requests. Next, it computes `required_size` by rounding the payload up for alignment and adding allocator overhead (headers/footers). It then calls `find_fit(required_size)` to locate a suitable free block. If a fit is found, `place` is called to mark the block allocated and split if needed, and `mm_malloc` returns a pointer to the payload. If no fit exists, `mm_malloc` extends the heap via `extend_heap`, coalesces the new space with neighbors, then calls `place` on the resulting free block. This sequence connects all prior components—size computation, placement policy, splitting, coalescing, and heap extension—into a working allocator.","notes_text":"This is the core you implement for MallocLab.","keywords":["mm_malloc","required_size","find_fit","extend_heap","place","allocation pipeline"],"images":[],"layout":{"num_text_boxes":2,"num_images":0,"dominant_visual_type":"text-heavy"},"metadata":{"course":"CS356","unit":12,"topic":"mm_malloc Flow","importance_score":9,"file_hash":"sha256_placeholder"}}
{"deck_name":"CS356_Unit12_HeapManagement","slide_number":31,"chunk_index":0,"title":"Explicit Free Lists (Structure)","summary":"Introduces explicit free lists and the metadata stored inside free blocks.","main_text":"Explicit free lists track only free blocks in a dedicated linked list. When a block is free, the allocator uses some of its payload space to store pointers to other free blocks—commonly `prev` and `next` in a doubly linked list. Allocated blocks omit these pointers and contain only user payload. Because searches traverse only free blocks, `find_fit` becomes faster than with implicit lists that must scan both allocated and free blocks. The cost is extra internal fragmentation for small blocks (free blocks must be big enough to hold the pointers) and more complex list maintenance: upon allocation, the block must be removed from the free list; upon freeing, it must be inserted back, possibly after coalescing.","notes_text":"Ordering can be by LIFO, address, or size; each affects fragmentation/perf.","keywords":["explicit free list","free block pointers","doubly linked list","find_fit speedup","minimum block size","metadata overhead"],"images":[],"layout":{"num_text_boxes":7,"num_images":0,"dominant_visual_type":"diagram"},"metadata":{"course":"CS356","unit":12,"topic":"Explicit Free Lists","importance_score":8,"file_hash":"sha256_placeholder"}}
{"deck_name":"CS356_Unit12_HeapManagement","slide_number":32,"chunk_index":0,"title":"Explicit Free Lists: Example and Ordering","summary":"Walks through how frees update the explicit list and discusses ordering choices.","main_text":"The example traces a sequence of allocations and frees to show how explicit free lists evolve. When blocks are freed, they are inserted into the free list and may later be coalesced with adjacent free blocks, requiring removal of the old nodes and insertion of the merged node. If coalescing is deferred, the free list can contain multiple free blocks in a time-based order rather than address order (e.g., blocks 3, 1, 4). The slide notes two alternative policies: maintaining the free list **sorted by address**, which simplifies coalescing and can reduce external fragmentation, or **sorted by size**, which approximates best-fit and can improve utilization. Each ordering affects throughput and fragmentation differently.","notes_text":"Key skill: correct prev/next pointer updates under all cases.","keywords":["explicit list example","free insertion","remove on alloc","list ordering","address-ordered","size-ordered"],"images":[],"layout":{"num_text_boxes":10,"num_images":0,"dominant_visual_type":"mixed"},"metadata":{"course":"CS356","unit":12,"topic":"Explicit Free List Example","importance_score":8,"file_hash":"sha256_placeholder"}}
{"deck_name":"CS356_Unit12_HeapManagement","slide_number":33,"chunk_index":0,"title":"Explicit Free Lists: Exercise","summary":"Exercise prompt to practice explicit free list updates and coalescing.","main_text":"This slide is an exercise checkpoint. You are expected to apply the explicit-free-list rules to a short allocation/free trace: remove allocated blocks from the free list, insert freed blocks, and coalesce adjacent free blocks when required. The purpose is to reinforce the invariant that the free list must remain well-formed and that coalescing must update both heap tags and list pointers consistently.","notes_text":"Work the trace and verify list invariants after each step.","keywords":["exercise","explicit free list","coalescing practice","list invariant","pointer updates"],"images":[],"layout":{"num_text_boxes":1,"num_images":0,"dominant_visual_type":"text-heavy"},"metadata":{"course":"CS356","unit":12,"topic":"Explicit Free List Exercise","importance_score":6,"file_hash":"sha256_placeholder"}}
{"deck_name":"CS356_Unit12_HeapManagement","slide_number":34,"chunk_index":0,"title":"Segregated Free Lists Overview","summary":"Introduces multiple free lists by size class and names segregated storage and segregated fit.","main_text":"Segregated free lists speed up allocation by keeping **separate free lists for different block sizes**. When malloc requests `size`, the allocator maps the request to a size class and searches only that list first; if empty, it searches progressively larger classes. This reduces search time and tends to match requests to closer-sized blocks, improving utilization compared to a single global list. Two main variants are presented: **segregated storage**, which uses fixed-size blocks per class and removes headers/coalescing, and **segregated fit**, which keeps variable-size blocks with boundary tags, splitting, and coalescing. The rest of the section expands each variant.","notes_text":"Think “bins by size.”","keywords":["segregated free lists","size classes","bins","segregated storage","segregated fit","fast search"],"images":[],"layout":{"num_text_boxes":2,"num_images":0,"dominant_visual_type":"text-heavy"},"metadata":{"course":"CS356","unit":12,"topic":"Segregated Free Lists","importance_score":8,"file_hash":"sha256_placeholder"}}
{"deck_name":"CS356_Unit12_HeapManagement","slide_number":35,"chunk_index":0,"title":"Segregated Storage (Mechanism)","summary":"Describes fixed-size class lists and how allocation and free work.","main_text":"Segregated storage splits the heap into multiple free lists of **fixed-size blocks**, such as 16-byte, 32-byte, 64-byte, and 4KB classes. For an allocation, the allocator chooses the smallest block size that can hold the requested payload and returns one block from that class list. If that list is empty, it extends the heap, partitions the new region into blocks of that size, and pushes them into the class list. Freeing is trivial: return the block to its corresponding class list, not necessarily in address order. Because all blocks in a class have identical size, headers/footers and coalescing are unnecessary, keeping metadata tiny and operations fast. The tradeoff is internal fragmentation when requests don’t align well with class sizes.","notes_text":"Very common for small-object allocators and slab allocators.","keywords":["segregated storage","fixed-size blocks","class lists","no coalescing","internal fragmentation","fast malloc/free"],"images":[],"layout":{"num_text_boxes":9,"num_images":0,"dominant_visual_type":"diagram"},"metadata":{"course":"CS356","unit":12,"topic":"Segregated Storage","importance_score":8,"file_hash":"sha256_placeholder"}}
{"deck_name":"CS356_Unit12_HeapManagement","slide_number":36,"chunk_index":0,"title":"Segregated Storage: Properties and Overlay","summary":"Lists key properties and shows how a free block overlays metadata onto payload space.","main_text":"Because distributed class lists use fixed block sizes, segregated storage can avoid boundary tags entirely. A free block is overlaid with a small struct that stores only the **next free pointer**; an allocated block uses the same bytes as payload. This allows singly linked lists, constant-time push/pop in each class, and very low overhead. The minimum block size equals one pointer, since a free block must store at least its `next` link. However, the simplicity comes at a cost: rounded-up allocations can waste space inside allocated blocks (internal fragmentation) and blocks in different classes can’t be coalesced. The overlay figure for a 16-byte class highlights the dual use: (free) `next + padding` versus (allocated) `payload`.","notes_text":"Overlay is why headers aren’t needed here.","keywords":["overlay","next pointer","fixed-size class","no headers/footers","minimum block size","internal fragmentation"],"images":[],"layout":{"num_text_boxes":8,"num_images":0,"dominant_visual_type":"mixed"},"metadata":{"course":"CS356","unit":12,"topic":"Segregated Storage Properties","importance_score":8,"file_hash":"sha256_placeholder"}}
{"deck_name":"CS356_Unit12_HeapManagement","slide_number":37,"chunk_index":0,"title":"Segregated Storage: Example","summary":"Example trace demonstrating class selection, reuse, and simple frees.","main_text":"This example shows a heap managed with segregated storage and multiple fixed-size free lists. A sequence of allocations maps each request to the smallest sufficient class, removes a block from that class list, and uses it as payload. When blocks are freed, they are returned to the correct class list (often LIFO), enabling quick reuse on later allocations of similar size. The example reinforces two crucial behaviors: (1) lists are independent, so allocation searches are short and skip irrelevant sizes, and (2) because blocks are fixed size, there is no splitting or coalescing—free operations are constant-time list insertions.","notes_text":"Focus on how internal fragmentation appears in fixed class systems.","keywords":["segregated storage example","size class mapping","constant-time free","reuse","no splitting","no coalescing"],"images":[],"layout":{"num_text_boxes":1,"num_images":0,"dominant_visual_type":"diagram"},"metadata":{"course":"CS356","unit":12,"topic":"Segregated Storage Example","importance_score":7,"file_hash":"sha256_placeholder"}}
{"deck_name":"CS356_Unit12_HeapManagement","slide_number":38,"chunk_index":0,"title":"Segregated Fit (Idea + First Example)","summary":"Introduces variable-size size classes with boundary tags and a small worked allocation example.","main_text":"Segregated fit keeps **multiple free lists by size range**, but unlike segregated storage, blocks within each class are variable sized and can be split/coalesced. This requires boundary tags (header/footer). Each list covers an interval such as [16–31], [32–63], and ≥64 bytes, and a free block belongs to the smallest interval that can contain its size. On malloc, the allocator searches the list matching the request first; if empty, it checks larger lists. When it finds a fit, it may split off a remainder and place that remainder back into the correct smaller class. The small example on the slide shows an initial state of size-class lists, then how a `malloc(32)` request consumes from a larger class and leaves a fragment inserted into a smaller class.","notes_text":"This approximates best-fit while avoiding tiny blocks.","keywords":["segregated fit","variable-size blocks","size intervals","boundary tags","split remainder","best-fit approximation"],"images":[],"layout":{"num_text_boxes":7,"num_images":0,"dominant_visual_type":"mixed"},"metadata":{"course":"CS356","unit":12,"topic":"Segregated Fit Intro","importance_score":9,"file_hash":"sha256_placeholder"}}
{"deck_name":"CS356_Unit12_HeapManagement","slide_number":39,"chunk_index":0,"title":"Segregated Fit (Algorithm Details)","summary":"Explains initialization, cross-class searching, splitting, and coalescing on free.","main_text":"At initialization, segregated fit may start with one large free block in the largest size class. As allocations proceed, blocks split and leftover fragments move down into smaller size classes. If the requested size class has no fitting block, the allocator searches larger classes in increasing order until a fit is found. If even the largest class is empty, the heap is extended. On free, the allocator coalesces the freed block with adjacent free neighbors (removing those neighbors from their current lists) and inserts the merged block into the size class matching its new size. This design improves throughput by shrinking search spaces while preserving utilization via splitting and coalescing.","notes_text":"Correctly moving blocks between classes is essential.","keywords":["segregated fit algorithm","search larger classes","heap extension","coalescing","class insertion","splitting"],"images":[],"layout":{"num_text_boxes":3,"num_images":0,"dominant_visual_type":"text-heavy"},"metadata":{"course":"CS356","unit":12,"topic":"Segregated Fit Algorithm","importance_score":9,"file_hash":"sha256_placeholder"}}
{"deck_name":"CS356_Unit12_HeapManagement","slide_number":40,"chunk_index":0,"title":"Segregated Fit: Extended Example","summary":"Step-by-step example showing searches across classes, splitting, and coalescing.","main_text":"The extended example traces segregated fit with several size-class free lists (e.g., free16, free32, free4k). For an allocation like `ptr1 = malloc(48)`, the allocator first searches the 32-class list and finds it empty, then moves to the next larger class. It allocates from an 80-byte free block, splits the block, and inserts the leftover fragment into the appropriate smaller class. Later, when a block such as `a2` is freed, the allocator coalesces it with neighboring free blocks, removes those neighbors from their lists, forms a larger combined free block, and inserts that combined block into the size class matching its new size. The “before/after malloc” and “before/after free(a2)” states illustrate how blocks migrate between classes and how segregated fit approximates best-fit without scanning tiny blocks.","notes_text":"Use this to sanity-check your own segregated fit logic.","keywords":["segregated fit example","class search","split block","insert fragment","coalesce neighbors","move between lists"],"images":[],"layout":{"num_text_boxes":10,"num_images":0,"dominant_visual_type":"mixed"},"metadata":{"course":"CS356","unit":12,"topic":"Segregated Fit Example","importance_score":9,"file_hash":"sha256_placeholder"}}
{"deck_name":"CS356_Unit12_HeapManagement","slide_number":41,"chunk_index":0,"title":"Garbage Collection (Section Header)","summary":"Transitions from explicit allocators to garbage collection.","main_text":"This slide marks the start of the garbage collection part of the unit. The focus shifts from manual allocation policies (implicit/explicit/segregated lists) to automatic memory reclamation strategies used by modern runtimes. The upcoming slides introduce GC motivations, main approaches, and performance tradeoffs.","notes_text":"","keywords":["garbage collection","section transition","automatic deallocation"],"images":[],"layout":{"num_text_boxes":1,"num_images":0,"dominant_visual_type":"text-heavy"},"metadata":{"course":"CS356","unit":12,"topic":"Garbage Collection Header","importance_score":6,"file_hash":"sha256_placeholder"}}
{"deck_name":"CS356_Unit12_HeapManagement","slide_number":42,"chunk_index":0,"title":"GC Approaches Overview","summary":"Motivates GC and identifies reference counting and tracing as two major families.","main_text":"Manual memory management is difficult and error-prone: programmers must free everything exactly once, or risk dangling pointers and memory leaks. Tools like Valgrind can detect leaks, but many languages adopt automated garbage collection. The slide highlights two broad GC approaches. **Reference counting** (including smart pointers) keeps a per-object count of active references and frees objects when counts hit zero. **Object graph analysis** (tracing GC) periodically traverses pointers from program roots to identify reachable objects and reclaims the rest. These two families trade incremental overhead (reference counting updates on every pointer change) against periodic global overhead and pauses (tracing).","notes_text":"Sets up the next deep-dive slides.","keywords":["GC approaches","valgrind","reference counting","smart pointers","tracing GC","object graph"],"images":[],"layout":{"num_text_boxes":2,"num_images":0,"dominant_visual_type":"text-heavy"},"metadata":{"course":"CS356","unit":12,"topic":"GC Approaches","importance_score":8,"file_hash":"sha256_placeholder"}}
{"deck_name":"CS356_Unit12_HeapManagement","slide_number":43,"chunk_index":0,"title":"Reference Counting Example","summary":"Shows how refcounts change with aliasing and deletion, and notes cycles as the key limitation.","main_text":"The Python REPL example demonstrates reference counting in practice. Creating `x = object()` establishes a baseline reference count. Assigning `y = x` creates a new alias, incrementing the count; deleting `y` decrements it. When an object’s count reaches zero, the runtime reclaims it immediately, which can cascade to other objects whose counts drop as a result. Reference counting provides prompt reclamation and tends to keep pauses small. However, the major limitation is **reference cycles**: if objects reference each other in a closed loop, their counts never fall to zero, even when the cycle is unreachable from roots. Languages using reference counting often add an extra tracing phase to collect cyclic garbage.","notes_text":"Python uses RC + periodic cycle detection.","keywords":["reference counting","Python example","getrefcount","aliasing","immediate reclamation","cycles"],"images":[],"layout":{"num_text_boxes":1,"num_images":0,"dominant_visual_type":"text-heavy"},"metadata":{"course":"CS356","unit":12,"topic":"Reference Counting","importance_score":9,"file_hash":"sha256_placeholder"}}
{"deck_name":"CS356_Unit12_HeapManagement","slide_number":44,"chunk_index":0,"title":"Tracing Garbage Collectors (Concept)","summary":"Defines tracing GC, roots, reachability, and stop-the-world behavior.","main_text":"Tracing garbage collectors reclaim memory based on reachability. When heap memory becomes scarce, the runtime identifies a set of **roots**: global variables, static class members, and local variables in active stack frames. Starting from these roots, it traverses the object graph by following pointers. Any object reached is considered live and kept; anything not reached is garbage and can be deallocated, including cyclic structures. A central drawback is that tracing typically requires pausing the program during traversal, a **stop-the-world (STW)** event. These pauses can be fast in modern collectors but occur at unpredictable times, affecting latency.","notes_text":"Used by Java, Go, JavaScript, etc.","keywords":["tracing GC","roots","reachability","object graph traversal","cycles collected","stop-the-world"],"images":[],"layout":{"num_text_boxes":6,"num_images":0,"dominant_visual_type":"text-heavy"},"metadata":{"course":"CS356","unit":12,"topic":"Tracing GC Concept","importance_score":9,"file_hash":"sha256_placeholder"}}
{"deck_name":"CS356_Unit12_HeapManagement","slide_number":45,"chunk_index":0,"title":"Tracing GC: Mark and Sweep","summary":"Explains the mark phase, sweep phase, and why fragmentation/scan cost arise.","main_text":"Mark-and-sweep GC runs in two phases. **Mark phase:** traverse from roots (often depth-first) and set a “reachable” mark bit in each visited object header. **Sweep phase:** scan all heap objects linearly; any object without its mark bit set is unreachable and is freed, while reachable objects have their mark bits cleared for the next cycle. This approach collects cyclic garbage because it uses reachability rather than counts. Its costs are (1) sweeping touches every object even if most are garbage, and (2) freeing objects in place can leave holes, causing fragmentation. To mitigate fragmentation, some implementations add a compacting step that relocates reachable objects together.","notes_text":"Contrast with stop-and-copy on next slide.","keywords":["mark and sweep","mark bit","sweep scan","reachability","fragmentation","compaction"],"images":[],"layout":{"num_text_boxes":12,"num_images":0,"dominant_visual_type":"flowchart"},"metadata":{"course":"CS356","unit":12,"topic":"Mark and Sweep GC","importance_score":9,"file_hash":"sha256_placeholder"}}
{"deck_name":"CS356_Unit12_HeapManagement","slide_number":46,"chunk_index":0,"title":"Tracing GC: Stop and Copy","summary":"Describes stop-and-copy collection to avoid sweep overhead and reduce fragmentation.","main_text":"Stop-and-copy GC divides the heap into two equal regions. The program allocates only in the active region. When GC runs, the runtime stops the program and traverses from roots; each reachable object is **copied** into the inactive region, leaving them packed contiguously. After traversal, the inactive region becomes the new active heap, and the old active region is considered entirely free—unreachable objects were never copied, so they are reclaimed implicitly. This eliminates the sweep scan and compacts memory automatically, preventing fragmentation. The drawback is that long-lived objects may be copied repeatedly each cycle, creating overhead for persistent data.","notes_text":"Motivates generational GC next.","keywords":["stop and copy","two-space heap","copy reachable objects","implicit sweep","compaction","long-lived overhead"],"images":[],"layout":{"num_text_boxes":11,"num_images":0,"dominant_visual_type":"diagram"},"metadata":{"course":"CS356","unit":12,"topic":"Stop and Copy GC","importance_score":9,"file_hash":"sha256_placeholder"}}
{"deck_name":"CS356_Unit12_HeapManagement","slide_number":47,"chunk_index":0,"title":"Generational GC and Heap Regions","summary":"Introduces the weak generational hypothesis and Eden/Survivor/Tenured regions.","main_text":"Generational GC relies on the **weak generational hypothesis**: most objects die young. The heap is partitioned into regions. New objects are allocated in **Eden**. When Eden fills, a young-generation collection copies live Eden objects into one of two **Survivor** spaces (S0 or S1). On subsequent young-gen collections, live objects are copied between S0 and S1, and a survival counter increments. Objects that survive enough cycles are **promoted** to the **Tenured (Old Gen)** region, which is collected less frequently and may use compaction to avoid fragmentation. By collecting young objects often and old objects rarely, generational GC greatly reduces the repeated copying cost of long-lived objects while keeping most collections fast.","notes_text":"This is the standard design in Java-like runtimes.","keywords":["generational GC","weak generational hypothesis","Eden","Survivor spaces","tenured/old gen","promotion"],"images":[],"layout":{"num_text_boxes":12,"num_images":0,"dominant_visual_type":"diagram"},"metadata":{"course":"CS356","unit":12,"topic":"Generational GC","importance_score":10,"file_hash":"sha256_placeholder"}}
{"deck_name":"CS356_Unit12_HeapManagement","slide_number":48,"chunk_index":0,"title":"Visual GC in Java","summary":"Visual illustration reinforcing object movement across Eden, Survivors, and Tenured.","main_text":"This slide provides a visual summary of Java’s generational garbage collection. It depicts allocations in Eden, copying of surviving objects into Survivor spaces during minor GCs, and promotion of older survivors into Tenured after multiple cycles. The illustration emphasizes how Java avoids scanning or copying long-lived objects too frequently and why young-gen collections are usually short but happen often.","notes_text":"Diagram-only reinforcement slide.","keywords":["Java GC","Eden to Survivor","minor GC","promotion","tenured region","diagram"],"images":[],"layout":{"num_text_boxes":1,"num_images":0,"dominant_visual_type":"diagram"},"metadata":{"course":"CS356","unit":12,"topic":"Java GC Visualization","importance_score":7,"file_hash":"sha256_placeholder"}}
{"deck_name":"CS356_Unit12_HeapManagement","slide_number":49,"chunk_index":0,"title":"GC Variations: Parallel and Concurrent","summary":"Summarizes parallel tracing and concurrent mark-and-sweep to reduce pauses.","main_text":"Two practical tracing-GC variations reduce stop-the-world time. **Parallel GC** uses multiple threads to traverse and copy/mark objects (especially in Eden and Survivor spaces), speeding up collections on multicore CPUs. **Concurrent mark-and-sweep** performs some marking and sweeping while the program continues running, improving responsiveness. However, concurrent collectors must monitor mutations to already-visited objects, because these changes can make previously unreachable objects reachable again. Even concurrent schemes retain some STW steps, such as when Eden fills or when Tenured promotion/compaction is required. The net effect is lower average pause time and better latency at the cost of more complex runtime bookkeeping.","notes_text":"Modern low-pause collectors combine both ideas.","keywords":["parallel GC","concurrent GC","concurrent mark and sweep","latency","STW steps","runtime bookkeeping"],"images":[],"layout":{"num_text_boxes":2,"num_images":0,"dominant_visual_type":"text-heavy"},"metadata":{"course":"CS356","unit":12,"topic":"GC Variations","importance_score":8,"file_hash":"sha256_placeholder"}}
{"deck_name":"CS356_Unit12_HeapManagement","slide_number":50,"chunk_index":0,"title":"Memory Leaks with GC","summary":"Explains why logical leaks still happen under garbage collection.","main_text":"Garbage collection prevents many low-level memory errors, but it cannot stop **logical memory leaks**. A GC frees only objects that are unreachable from roots. If the program retains references to objects it no longer needs—such as entries left in global caches, long-lived lists, or closures attached to event handlers—those objects remain reachable and will not be collected. Over time, this increases the live set and can exhaust memory even in a garbage-collected language. Preventing these leaks requires correct application-level ownership and lifecycle design, not just a GC runtime.","notes_text":"Key takeaway: reachability ≠ usefulness.","keywords":["GC memory leaks","logical leak","reachable objects","roots","caches","lifecycle management"],"images":[],"layout":{"num_text_boxes":1,"num_images":0,"dominant_visual_type":"text-heavy"},"metadata":{"course":"CS356","unit":12,"topic":"Memory Leaks with GC","importance_score":8,"file_hash":"sha256_placeholder"}}
